{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f279fb15",
   "metadata": {},
   "source": [
    "# Week 4 - Data Wrangling and Group-Based Aggregations\n",
    "\n",
    "In this notebook we will practice data cleaning and group-based aggregations using a *messy* version of the german credit risk dataset.\n",
    "\n",
    "Dataset reference: ðŸ”— https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
    "\n",
    "Topics covered:\n",
    "- Concatenating DataFrames\n",
    "- Preprocessing\n",
    "    - Categorical x Numerical Data\n",
    "    - Fixing column types\n",
    "    - Standardizing Categorical Values\n",
    "    - Missing values (Identifying and Imputation)\n",
    "- Group-Based Aggregations\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e4e90ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a4634",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "> When loading the German Credit dataset from the UCI repository, you will notice\n",
    "> that the data is split into **two separate DataFrames**:\n",
    ">\n",
    "> - `X` contains all feature columns (Attribute1 â€¦ Attribute20)\n",
    "> - `y` contains the target variable (`class`)\n",
    ">\n",
    "> This separation is common in Machine Learning libraries because it clearly\n",
    "> distinguishes:\n",
    ">\n",
    "> - **independent variables** â†’ used to make predictions  \n",
    "> - **dependent variable** â†’ the value we want to predict\n",
    ">\n",
    "> However, for **Exploratory Data Analysis (EDA)**, it is usually more convenient\n",
    "> to work with a **single unified table**.\n",
    ">\n",
    "> Having both features and the target in the same DataFrame simplifies:\n",
    ">\n",
    "> - inspecting the overall structure  \n",
    "> - checking distributions  \n",
    "> - computing correlations  \n",
    "> - detecting missing values  \n",
    "> - visualizing relationships between variables\n",
    ">\n",
    "> To prepare for EDA, we will **concatenate** the two parts into one unified table.\n",
    ">\n",
    "> ### Concatenating DataFrames\n",
    ">\n",
    "> The simplest way to combine `X` and `y` is with `pd.concat`, which allows us to\n",
    "> join DataFrames **side-by-side** using `axis=1`:\n",
    ">\n",
    "> - `pd.concat([...])` â†’ specifies the DataFrames to combine  \n",
    "> - `axis=1` or `axis='columns'` â†’ concatenate **column-wise**, placing the\n",
    ">   target column next to the features  \n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ```python\n",
    "> df = pd.concat([df_1, df_2], axis=1)\n",
    ">\n",
    "> # or equivalently\n",
    ">\n",
    "> df = pd.concat([df_1, df_2], axis=\"columns\")\n",
    "> ```\n",
    ">\n",
    "> ### What about `axis=0` or `axis='rows'`?\n",
    ">\n",
    "> - This stacks DataFrames **row-wise**, one on top of the other.  \n",
    "> - It requires both DataFrames to have the **same columns**.  \n",
    "> - Therefore it is *not* appropriate for joining `X` and `y`.\n",
    "\n",
    "---\n",
    "\n",
    "### Q1.1 Load both datasets in separate DataFrames `X` and `y`, then concatenate them into one using `pd.concat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba60a20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute12</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute14</th>\n",
       "      <th>Attribute15</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute17</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute19</th>\n",
       "      <th>Attribute20</th>\n",
       "      <th>Attribute21</th>\n",
       "      <th>Attribute22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>67.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>a152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a192</td>\n",
       "      <td>A201</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>a32</td>\n",
       "      <td>a43</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>a61</td>\n",
       "      <td>a73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a121</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a191</td>\n",
       "      <td>A201</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>a74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a122</td>\n",
       "      <td>45.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A124</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>24.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute1  Attribute2 Attribute3 Attribute4  Attribute5 Attribute6  \\\n",
       "0        A11         6.0        A34        A43      1169.0       A65    \n",
       "1        A12        48.0        a32        a43      5951.0       a61    \n",
       "2        A14        12.0        A34        A46      2096.0       A61    \n",
       "3        a11        42.0        A32        A42      7882.0       A61    \n",
       "4        a11        24.0        A33        A40      4870.0       A61    \n",
       "\n",
       "  Attribute7  Attribute8 Attribute9 Attribute10  Attribute11 Attribute12  \\\n",
       "0        A75         NaN        A93        A101          4.0        A121   \n",
       "1        a73         2.0        A92        A101          2.0        a121   \n",
       "2        A74         2.0        A93        A101          3.0        A121   \n",
       "3        a74         2.0        A93        A103          4.0        a122   \n",
       "4        A73         3.0        A93        A101          4.0        A124   \n",
       "\n",
       "   Attribute13 Attribute14 Attribute15  Attribute16 Attribute17  Attribute18  \\\n",
       "0         67.0        A143        a152          2.0         NaN          1.0   \n",
       "1         22.0         NaN        A152          1.0         NaN          1.0   \n",
       "2         49.0        A143        A152          1.0        a172          2.0   \n",
       "3         45.0        A143        A153          1.0         NaN          2.0   \n",
       "4         53.0         NaN        a153          2.0        A173          2.0   \n",
       "\n",
       "  Attribute19 Attribute20  Attribute21 Attribute22  \n",
       "0        a192        A201          6.0         NaN  \n",
       "1        a191        A201         48.0         NaN  \n",
       "2        A191        A201         12.0         NaN  \n",
       "3        A191        A201         42.0         NaN  \n",
       "4        A191        A201         24.0          99  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X = pd.read_csv('X_gcd.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "edd01f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class\n",
       "0  good\n",
       "1   bad\n",
       "2  good\n",
       "3  good\n",
       "4   bad"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y = pd.read_csv('y_gcd.csv')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "473af762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute12</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute14</th>\n",
       "      <th>Attribute15</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute17</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute19</th>\n",
       "      <th>Attribute20</th>\n",
       "      <th>Attribute21</th>\n",
       "      <th>Attribute22</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>67.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>a152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a192</td>\n",
       "      <td>A201</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>a32</td>\n",
       "      <td>a43</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>a61</td>\n",
       "      <td>a73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a121</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a191</td>\n",
       "      <td>A201</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>a74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a122</td>\n",
       "      <td>45.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A124</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>24.0</td>\n",
       "      <td>99</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute1  Attribute2 Attribute3 Attribute4  Attribute5 Attribute6  \\\n",
       "0        A11         6.0        A34        A43      1169.0       A65    \n",
       "1        A12        48.0        a32        a43      5951.0       a61    \n",
       "2        A14        12.0        A34        A46      2096.0       A61    \n",
       "3        a11        42.0        A32        A42      7882.0       A61    \n",
       "4        a11        24.0        A33        A40      4870.0       A61    \n",
       "\n",
       "  Attribute7  Attribute8 Attribute9 Attribute10  Attribute11 Attribute12  \\\n",
       "0        A75         NaN        A93        A101          4.0        A121   \n",
       "1        a73         2.0        A92        A101          2.0        a121   \n",
       "2        A74         2.0        A93        A101          3.0        A121   \n",
       "3        a74         2.0        A93        A103          4.0        a122   \n",
       "4        A73         3.0        A93        A101          4.0        A124   \n",
       "\n",
       "   Attribute13 Attribute14 Attribute15  Attribute16 Attribute17  Attribute18  \\\n",
       "0         67.0        A143        a152          2.0         NaN          1.0   \n",
       "1         22.0         NaN        A152          1.0         NaN          1.0   \n",
       "2         49.0        A143        A152          1.0        a172          2.0   \n",
       "3         45.0        A143        A153          1.0         NaN          2.0   \n",
       "4         53.0         NaN        a153          2.0        A173          2.0   \n",
       "\n",
       "  Attribute19 Attribute20  Attribute21 Attribute22 class  \n",
       "0        a192        A201          6.0         NaN  good  \n",
       "1        a191        A201         48.0         NaN   bad  \n",
       "2        A191        A201         12.0         NaN  good  \n",
       "3        A191        A201         42.0         NaN  good  \n",
       "4        A191        A201         24.0          99   bad  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13525f2",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    ">\n",
    ">Below is the official data dictionary for the German Credit dataset.  \n",
    ">\n",
    ">Notice how the variables are originally labeled as `Attribute1`, `Attribute2`, â€¦ `Attribute20`.  \n",
    ">\n",
    ">Although this scheme preserves the order of the variables, it is **not descriptive**, which makes the dataset hard to read during analysis.\n",
    ">\n",
    ">| Variable Name | Role    | Type         | Demographic     | Description                                             | Units |\n",
    ">|---------------|---------|--------------|-----------------|---------------------------------------------------------|-------|\n",
    ">| Attribute1    | Feature | Categorical  |                 | Status of existing checking account                     |       |\n",
    ">| Attribute2    | Feature | Integer      |                 | Duration                                                | months|\n",
    ">| Attribute3    | Feature | Categorical  |                 | Credit history                                          |       |\n",
    ">| Attribute4    | Feature | Categorical  |                 | Purpose                                                 |       |\n",
    ">| Attribute5    | Feature | Integer      |                 | Credit amount                                           |       |\n",
    ">| Attribute6    | Feature | Categorical  |                 | Savings account/bonds                                   |       |\n",
    ">| Attribute7    | Feature | Categorical  | Other           | Present employment since                                |       |\n",
    ">| Attribute8    | Feature | Integer      |                 | Installment rate as % of disposable income              |       |\n",
    ">| Attribute9    | Feature | Categorical  | Marital Status  | Personal status and sex                                 |       |\n",
    ">| Attribute10   | Feature | Categorical  |                 | Other debtors / guarantors                              |       |\n",
    ">| Attribute11   | Feature | Integer      |                 | Present residence since                                 |       |\n",
    ">| Attribute12   | Feature | Categorical  |                 | Property owned                                          |       |\n",
    ">| Attribute13   | Feature | Integer      | Age             | Age                                                     | years |\n",
    ">| Attribute14   | Feature | Categorical  |                 | Other installment plans                                 |       |\n",
    ">| Attribute15   | Feature | Categorical  | Other           | Housing                                                 |       |\n",
    ">| Attribute16   | Feature | Integer      |                 | Number of existing credits at this bank                 |       |\n",
    ">| Attribute17   | Feature | Categorical  | Occupation      | Job                                                     |       |\n",
    ">| Attribute18   | Feature | Integer      |                 | Number of dependents                                    |       |\n",
    ">| Attribute19   | Feature | Binary       |                 | Telephone                                               |       |\n",
    ">| Attribute20   | Feature | Binary       | Other           | Foreign worker                                          |       |\n",
    ">| class         | Target  | Binary       |                 | 1 = Good, 2 = Bad                                       |       |\n",
    "---\n",
    "## 2. Clean the Data\n",
    "\n",
    "> You may have noticed that the column names are mostly **impractical for quick or direct analysis**.\n",
    ">\n",
    "> Labels like `Attribute3` or `Attribute14` do not convey meaning and force us to constantly consult the data dictionary.\n",
    ">\n",
    "> Before doing any EDA, it is important to assign **clear, consistent, and descriptive** column names.\n",
    "> This improves:\n",
    ">\n",
    "> - readability  \n",
    "> - visualization and plotting  \n",
    "> - correlation analysis  \n",
    "> - interpretability of models later on\n",
    "\n",
    "---\n",
    "\n",
    "### Q2. Use the dictionary below to rename all columns to meaningful, standardized names.\n",
    " \n",
    "- Apply it using `.rename(columns=...)` right after concatenating `X` and `y`.\n",
    "\n",
    "```python\n",
    "rename_dict = {\n",
    "    \"Attribute1\":  \"checking_status\",\n",
    "    \"Attribute2\":  \"duration_months\",\n",
    "    \"Attribute3\":  \"credit_history\",\n",
    "    \"Attribute4\":  \"purpose\",\n",
    "    \"Attribute5\":  \"credit_amount\",\n",
    "    \"Attribute6\":  \"savings_account\",\n",
    "    \"Attribute7\":  \"employment_since\",\n",
    "    \"Attribute8\":  \"installment_rate\",\n",
    "    \"Attribute9\":  \"personal_status_sex\",\n",
    "    \"Attribute10\": \"other_debtors\",\n",
    "    \"Attribute11\": \"residence_since\",\n",
    "    \"Attribute12\": \"property\",\n",
    "    \"Attribute13\": \"age\",\n",
    "    \"Attribute14\": \"other_installment_plans\",\n",
    "    \"Attribute15\": \"housing\",\n",
    "    \"Attribute16\": \"existing_credits\",\n",
    "    \"Attribute17\": \"job\",\n",
    "    \"Attribute18\": \"dependents\",\n",
    "    \"Attribute19\": \"telephone\",\n",
    "    \"Attribute20\": \"foreign_worker\",\n",
    "    \"class\":       \"credit_risk\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "29daf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"Attribute1\":  \"checking_status\",\n",
    "    \"Attribute2\":  \"duration_months\",\n",
    "    \"Attribute3\":  \"credit_history\",\n",
    "    \"Attribute4\":  \"purpose\",\n",
    "    \"Attribute5\":  \"credit_amount\",\n",
    "    \"Attribute6\":  \"savings_account\",\n",
    "    \"Attribute7\":  \"employment_since\",\n",
    "    \"Attribute8\":  \"installment_rate\",\n",
    "    \"Attribute9\":  \"personal_status_sex\",\n",
    "    \"Attribute10\": \"other_debtors\",\n",
    "    \"Attribute11\": \"residence_since\",\n",
    "    \"Attribute12\": \"property\",\n",
    "    \"Attribute13\": \"age\",\n",
    "    \"Attribute14\": \"other_installment_plans\",\n",
    "    \"Attribute15\": \"housing\",\n",
    "    \"Attribute16\": \"existing_credits\",\n",
    "    \"Attribute17\": \"job\",\n",
    "    \"Attribute18\": \"dependents\",\n",
    "    \"Attribute19\": \"telephone\",\n",
    "    \"Attribute20\": \"foreign_worker\",\n",
    "    \"Attribute21\": \"months\",\n",
    "    \"Attribute22\": \"postal_area\",\n",
    "    \"class\":       \"credit_risk\"\n",
    "    \n",
    "}\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ec77b",
   "metadata": {},
   "source": [
    "### Q2.1 Obtain the `.info()` from the Dataset:\n",
    "\n",
    ">Investigate the datatypes of each column. Are they appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0f0f1b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 23 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Attribute1   946 non-null    object \n",
      " 1   Attribute2   949 non-null    float64\n",
      " 2   Attribute3   946 non-null    object \n",
      " 3   Attribute4   954 non-null    object \n",
      " 4   Attribute5   931 non-null    float64\n",
      " 5   Attribute6   1000 non-null   object \n",
      " 6   Attribute7   960 non-null    object \n",
      " 7   Attribute8   944 non-null    float64\n",
      " 8   Attribute9   948 non-null    object \n",
      " 9   Attribute10  951 non-null    object \n",
      " 10  Attribute11  949 non-null    float64\n",
      " 11  Attribute12  940 non-null    object \n",
      " 12  Attribute13  963 non-null    float64\n",
      " 13  Attribute14  945 non-null    object \n",
      " 14  Attribute15  951 non-null    object \n",
      " 15  Attribute16  939 non-null    float64\n",
      " 16  Attribute17  943 non-null    object \n",
      " 17  Attribute18  955 non-null    float64\n",
      " 18  Attribute19  965 non-null    object \n",
      " 19  Attribute20  954 non-null    object \n",
      " 20  Attribute21  949 non-null    float64\n",
      " 21  Attribute22  160 non-null    object \n",
      " 22  class        958 non-null    object \n",
      "dtypes: float64(8), object(15)\n",
      "memory usage: 179.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c686704",
   "metadata": {},
   "source": [
    "### Q2.2 Obtain descriptive statistics using `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "181f4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>949.000000</td>\n",
       "      <td>931.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>949.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.989463</td>\n",
       "      <td>3259.498389</td>\n",
       "      <td>2.962924</td>\n",
       "      <td>2.839831</td>\n",
       "      <td>36.151610</td>\n",
       "      <td>1.401491</td>\n",
       "      <td>1.159162</td>\n",
       "      <td>20.989463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.051222</td>\n",
       "      <td>2807.398373</td>\n",
       "      <td>1.117537</td>\n",
       "      <td>1.102191</td>\n",
       "      <td>16.746982</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.366019</td>\n",
       "      <td>12.051222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2320.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attribute2    Attribute5  Attribute8  Attribute11  Attribute13  \\\n",
       "count  949.000000    931.000000  944.000000   949.000000   963.000000   \n",
       "mean    20.989463   3259.498389    2.962924     2.839831    36.151610   \n",
       "std     12.051222   2807.398373    1.117537     1.102191    16.746982   \n",
       "min      4.000000    276.000000    1.000000     1.000000    -5.000000   \n",
       "25%     12.000000   1365.000000    2.000000     2.000000    26.000000   \n",
       "50%     18.000000   2320.000000    3.000000     3.000000    33.000000   \n",
       "75%     24.000000   3974.000000    4.000000     4.000000    42.000000   \n",
       "max     72.000000  18424.000000    4.000000     4.000000   150.000000   \n",
       "\n",
       "       Attribute16  Attribute18  Attribute21  \n",
       "count   939.000000   955.000000   949.000000  \n",
       "mean      1.401491     1.159162    20.989463  \n",
       "std       0.572689     0.366019    12.051222  \n",
       "min       1.000000     1.000000     4.000000  \n",
       "25%       1.000000     1.000000    12.000000  \n",
       "50%       1.000000     1.000000    18.000000  \n",
       "75%       2.000000     1.000000    24.000000  \n",
       "max       4.000000     2.000000    72.000000  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa854d7",
   "metadata": {},
   "source": [
    "### Q2.3 Investigate how many missing values are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ad1f9f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attribute1      54\n",
       "Attribute2      51\n",
       "Attribute3      54\n",
       "Attribute4      46\n",
       "Attribute5      69\n",
       "Attribute6       0\n",
       "Attribute7      40\n",
       "Attribute8      56\n",
       "Attribute9      52\n",
       "Attribute10     49\n",
       "Attribute11     51\n",
       "Attribute12     60\n",
       "Attribute13     37\n",
       "Attribute14     55\n",
       "Attribute15     49\n",
       "Attribute16     61\n",
       "Attribute17     57\n",
       "Attribute18     45\n",
       "Attribute19     35\n",
       "Attribute20     46\n",
       "Attribute21     51\n",
       "Attribute22    840\n",
       "class           42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you code here\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0ee24",
   "metadata": {},
   "source": [
    "### Q2.4 Create `numerical` and `categorical` lists\n",
    "- you can check based on dtype (`'O'`) for object\n",
    "- you can also check using `df.select_dtypes(include=object)` or `np.number` for numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "44382325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attribute2',\n",
       " 'Attribute5',\n",
       " 'Attribute8',\n",
       " 'Attribute11',\n",
       " 'Attribute13',\n",
       " 'Attribute16',\n",
       " 'Attribute18',\n",
       " 'Attribute21']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "numerical = df.select_dtypes(include=np.number).columns.to_list()\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "033eacdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attribute1',\n",
       " 'Attribute3',\n",
       " 'Attribute4',\n",
       " 'Attribute6',\n",
       " 'Attribute7',\n",
       " 'Attribute9',\n",
       " 'Attribute10',\n",
       " 'Attribute12',\n",
       " 'Attribute14',\n",
       " 'Attribute15',\n",
       " 'Attribute17',\n",
       " 'Attribute19',\n",
       " 'Attribute20',\n",
       " 'Attribute22',\n",
       " 'class']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "categorical = df.select_dtypes(include=object).columns.to_list()\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "435b0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b789701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4b22f",
   "metadata": {},
   "source": [
    "### Q2.5 Standardize categorical columns\n",
    "\n",
    "- if possible, define strategies that could be used in columns with the same problem\n",
    "- if there are distinct problems, create lists containing a subset of columns with the same problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "91b93981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1\n",
      "A14    308\n",
      "A11    212\n",
      "A12    207\n",
      "a14     67\n",
      "A13     49\n",
      "a12     48\n",
      "a11     45\n",
      "a13     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute3\n",
      "A32    422\n",
      "A34    241\n",
      "a32     79\n",
      "A33     68\n",
      "A31     44\n",
      "a34     37\n",
      "A30     34\n",
      "a33     13\n",
      "a30      4\n",
      "a31      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute4\n",
      "A43     227\n",
      "A40     186\n",
      "A42     153\n",
      "A41      85\n",
      "A49      81\n",
      "a43      43\n",
      "A46      41\n",
      "a40      36\n",
      "A45      21\n",
      "a42      18\n",
      "a41      14\n",
      "A410     12\n",
      "A44      11\n",
      "a49      10\n",
      "a46       7\n",
      "A48       7\n",
      "a48       1\n",
      "a44       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute6\n",
      "A61     469\n",
      "A65     140\n",
      "a61     100\n",
      "A62      89\n",
      "A63      48\n",
      "nan      47\n",
      "A64      38\n",
      "a65      34\n",
      "a63      14\n",
      "a62      13\n",
      "a64       8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute7\n",
      "A73        279\n",
      "A75        200\n",
      "A72        140\n",
      "A74        138\n",
      "a73         47\n",
      "A71         47\n",
      "a75         39\n",
      "a72         25\n",
      "a74         24\n",
      "a71         11\n",
      "unknown     10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute9\n",
      "A93    424\n",
      "A92    242\n",
      "a93     86\n",
      "A94     68\n",
      "a92     49\n",
      "A91     41\n",
      "a94     22\n",
      "??      10\n",
      "a91      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute10\n",
      "A101    717\n",
      "a101    145\n",
      "A103     44\n",
      "A102     34\n",
      "a103      6\n",
      "a102      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute12\n",
      "A123    267\n",
      "A121    212\n",
      "A122    180\n",
      "A124    120\n",
      "a121     50\n",
      "a123     46\n",
      "a122     39\n",
      "a124     26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute14\n",
      "A143    645\n",
      "a143    125\n",
      "A141    113\n",
      "A142     35\n",
      "a141     19\n",
      "a142      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute15\n",
      "A152    568\n",
      "A151    143\n",
      "a152    109\n",
      "A153     86\n",
      "a151     29\n",
      "a153     16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute17\n",
      "A173    503\n",
      "A172    163\n",
      "A174    122\n",
      "a173     86\n",
      "a172     26\n",
      "a174     23\n",
      "A171     18\n",
      "a171      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute19\n",
      "A191    481\n",
      "A192    313\n",
      "a191     95\n",
      "a192     76\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute20\n",
      "A201    766\n",
      "a201    151\n",
      "A202     34\n",
      "a202      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attribute22\n",
      "      111\n",
      "99     49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "class\n",
      "good    639\n",
      "bad     269\n",
      "2        25\n",
      "1        25\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for col in categorical:\n",
    "    print(f'{df[col].value_counts()}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "511309d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# as we can see, there are columns with values in different case, mix of values as strings and integers, presence of weird symbols such as '??' and even ' ', ' nan ', 'unknown' and values that could be striped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e5931707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1\n",
      "['A11' 'A12' 'A14' 'a11' 'a12' 'a14' nan 'A13' 'a13']\n",
      "\n",
      "Attribute3\n",
      "['A34' 'a32' 'A32' 'A33' nan 'A30' 'A31' 'a33' 'a34' 'a30' 'a31']\n",
      "\n",
      "Attribute4\n",
      "['A43' 'a43' 'A46' 'A42' 'A40' 'a46' nan 'A49' 'a40' 'A41' 'A44' 'A45'\n",
      " 'a41' 'a42' 'a49' 'A410' 'A48' 'a48' 'a44']\n",
      "\n",
      "Attribute6\n",
      "[' A65 ' ' a61 ' ' A61 ' ' a65 ' ' A63 ' ' A64 ' ' A62 ' ' nan ' ' a64 '\n",
      " ' a63 ' ' a62 ']\n",
      "\n",
      "Attribute7\n",
      "['A75' 'a73' 'A74' 'a74' 'A73' 'a71' 'A72' 'a75' 'A71' 'a72' nan 'unknown']\n",
      "\n",
      "Attribute9\n",
      "['A93' 'A92' 'a93' 'A91' nan 'a92' 'A94' '??' 'a94' 'a91']\n",
      "\n",
      "Attribute10\n",
      "['A101' 'A103' nan 'A102' 'a101' 'a103' 'a102']\n",
      "\n",
      "Attribute12\n",
      "['A121' 'a121' 'a122' 'A124' 'A122' 'A123' 'a123' nan 'a124']\n",
      "\n",
      "Attribute14\n",
      "['A143' nan 'a143' 'A141' 'a141' 'A142' 'a142']\n",
      "\n",
      "Attribute15\n",
      "['a152' 'A152' 'A153' 'a153' 'A151' nan 'a151']\n",
      "\n",
      "Attribute17\n",
      "[nan 'a172' 'A173' 'A172' 'A174' 'a173' 'A171' 'a174' 'a171']\n",
      "\n",
      "Attribute19\n",
      "['a192' 'a191' 'A191' 'A192' nan]\n",
      "\n",
      "Attribute20\n",
      "['A201' nan 'a201' 'a202' 'A202']\n",
      "\n",
      "Attribute22\n",
      "[nan '99' ' ']\n",
      "\n",
      "class\n",
      "['good' 'bad' nan '2' '1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets use .unique() now because it will indicate also nans present in each column\n",
    "for col in categorical:\n",
    "    print(f'{col}\\n{df[col].unique()}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "81c4a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_categorical_column(series, special_na_values=None):\n",
    "    \"\"\"\n",
    "    Cleans a categorical column by fixing:\n",
    "    - extra whitespace\n",
    "    - mixed upper/lowercase\n",
    "    - string values representing NA\n",
    "    - strange symbols (??, '', ' ')\n",
    "    - mixed data types (int/float + string)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Column to clean.\n",
    "\n",
    "    special_na_values : list\n",
    "        Optional list of values that should be treated as NaN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Cleaned categorical column.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convert everything to string (preserving NA values)\n",
    "    s = series.astype(\"string\")\n",
    "\n",
    "    # 2. Strip leading/trailing whitespace\n",
    "    s = s.str.strip()\n",
    "\n",
    "    # 3. Normalize casing: convert to lowercase first\n",
    "    s = s.str.lower()\n",
    "\n",
    "    # 4. Define values that should be treated as missing (NaN)\n",
    "    default_na = {\"nan\", \"none\", \"null\", \"\", \" \", \"??\", \"unknown\"}\n",
    "    if special_na_values:\n",
    "        # Add custom NA values\n",
    "        default_na.update({v.lower() for v in special_na_values})\n",
    "\n",
    "    # Replace NA-like strings with actual NaN\n",
    "    s = s.replace(default_na, np.nan)\n",
    "\n",
    "    # 5. Standardize label format: convert strings like \"a11\" â†’ \"A11\"\n",
    "    # (only if the value starts with a letter)\n",
    "    s = s.apply(lambda x: x.upper() if isinstance(x, str) and x and x[0].isalpha() else x)\n",
    "\n",
    "    # 6. Convert numeric strings to integers (optional behavior)\n",
    "    s = s.apply(lambda x: int(x) if isinstance(x, str) and x.isdigit() else x)\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "69ae5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets clean now applyng the function to all columns\n",
    "for col in categorical:\n",
    "    df[col] = clean_categorical_column(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "843e3bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1\n",
      "['A11' 'A12' 'A14' <NA> 'A13']\n",
      "\n",
      "Attribute3\n",
      "['A34' 'A32' 'A33' <NA> 'A30' 'A31']\n",
      "\n",
      "Attribute4\n",
      "['A43' 'A46' 'A42' 'A40' <NA> 'A49' 'A41' 'A44' 'A45' 'A410' 'A48']\n",
      "\n",
      "Attribute6\n",
      "['A65' 'A61' 'A63' 'A64' 'A62' <NA>]\n",
      "\n",
      "Attribute7\n",
      "['A75' 'A73' 'A74' 'A71' 'A72' <NA>]\n",
      "\n",
      "Attribute9\n",
      "['A93' 'A92' 'A91' <NA> 'A94']\n",
      "\n",
      "Attribute10\n",
      "['A101' 'A103' <NA> 'A102']\n",
      "\n",
      "Attribute12\n",
      "['A121' 'A122' 'A124' 'A123' <NA>]\n",
      "\n",
      "Attribute14\n",
      "['A143' <NA> 'A141' 'A142']\n",
      "\n",
      "Attribute15\n",
      "['A152' 'A153' 'A151' <NA>]\n",
      "\n",
      "Attribute17\n",
      "[<NA> 'A172' 'A173' 'A174' 'A171']\n",
      "\n",
      "Attribute19\n",
      "['A192' 'A191' <NA>]\n",
      "\n",
      "Attribute20\n",
      "['A201' <NA> 'A202']\n",
      "\n",
      "Attribute22\n",
      "[<NA> 99]\n",
      "\n",
      "class\n",
      "['GOOD' 'BAD' <NA> 2 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets verify again\n",
    "for col in categorical:\n",
    "    print(f'{col}\\n{df[col].unique()}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dc2152e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    664\n",
       "2    294\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nan values are expected, but we can see now that the class column still has mix values\n",
    "# lets map those values according to the Data Dictionary where 1 = Good, 2 = Bad\n",
    "# Replace text values with numeric dictionary values\n",
    "mapping = {\n",
    "    \"GOOD\": 1,\n",
    "    \"BAD\": 2,\n",
    "}\n",
    "\n",
    "df[\"class\"] = df[\"class\"].replace(mapping)\n",
    "\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97530ab4",
   "metadata": {},
   "source": [
    "### Q2.6 Verify the percentage of missing values in each `categorical` column:\n",
    "- if it's below `5%`, input the `Mode` (this may not be the best approach but we are cleaning the best we can with what we have learned so far)\n",
    "- if it's above `40%` drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "704a6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1 -> 5.4 %\n",
      "Attribute3 -> 5.4 %\n",
      "Attribute4 -> 4.6 %\n",
      "Attribute6 -> 4.7 %\n",
      "Attribute7 -> 5.0 %\n",
      "Attribute9 -> 6.2 %\n",
      "Attribute10 -> 4.9 %\n",
      "Attribute12 -> 6.0 %\n",
      "Attribute14 -> 5.5 %\n",
      "Attribute15 -> 4.9 %\n",
      "Attribute17 -> 5.7 %\n",
      "Attribute19 -> 3.5000000000000004 %\n",
      "Attribute20 -> 4.6 %\n",
      "Attribute22 -> 95.1 %\n",
      "class -> 4.2 %\n"
     ]
    }
   ],
   "source": [
    "for col in categorical:\n",
    "    print(f'{col} -> {(df[col].isnull().sum()/df.shape[0]) * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7635269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop the column\n",
    "df.drop(columns=['Attribute22'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "57812043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets verify if the column was indeed dropped\n",
    "'Attribute22' in df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdd72d",
   "metadata": {},
   "source": [
    "### Q2.7. Verify the percentage of missing values in each `numerical` column\n",
    "- if it's above `40%` drop the column\n",
    "- inpute the `mean`, `median` or `mode`, decide yourself which you are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "afaa538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute2 -> 5.1 %\n",
      "Attribute5 -> 6.9 %\n",
      "Attribute8 -> 5.6000000000000005 %\n",
      "Attribute11 -> 5.1 %\n",
      "Attribute13 -> 3.6999999999999997 %\n",
      "Attribute16 -> 6.1 %\n",
      "Attribute18 -> 4.5 %\n",
      "Attribute21 -> 5.1 %\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "    print(f'{col} -> {(df[col].isnull().sum()/df.shape[0]) * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6726d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed median (18.0) for column 'Attribute2'\n",
      "\n",
      "Imputed median (2320.0) for column 'Attribute5'\n",
      "\n",
      "Imputed median (3.0) for column 'Attribute8'\n",
      "\n",
      "Imputed median (3.0) for column 'Attribute11'\n",
      "\n",
      "Imputed median (33.0) for column 'Attribute13'\n",
      "\n",
      "Imputed median (1.0) for column 'Attribute16'\n",
      "\n",
      "Imputed median (1.0) for column 'Attribute18'\n",
      "\n",
      "Imputed median (18.0) for column 'Attribute21'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_value = df[col].median()\n",
    "        df[col] = df[col].fillna(median_value)   # âœ” no chained assignment\n",
    "        print(f\"Imputed median ({median_value}) for column '{col}'\\n\")\n",
    "    else:\n",
    "        print(f\"No imputation needed for '{col}'\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075ea92",
   "metadata": {},
   "source": [
    "### Q2.8 Verify if there are **outliers** in `numerical` columns using the `IQR method`\n",
    "\n",
    "> To detect outliers in a numerical column, we can use the **Interquartile Range (IQR) method**.\n",
    "> The IQR represents the spread of the middle 50% of the data.\n",
    ">\n",
    "> The formula works as follows:\n",
    ">\n",
    "> - Compute the 1st quartile (Q1) â†’ 25th percentile  \n",
    "> - Compute the 3rd quartile (Q3) â†’ 75th percentile  \n",
    "> - Compute the **IQR**:\n",
    ">\n",
    "> $$\n",
    "> \\text{IQR} = Q3 - Q1\n",
    "> $$\n",
    ">\n",
    "> Outliers are any observations outside the following bounds:\n",
    ">\n",
    "> $$\n",
    "> \\text{Lower Bound} = Q1 - 1.5 \\times \\text{IQR}\n",
    "> $$\n",
    "> $$\n",
    "> \\text{Upper Bound} = Q3 + 1.5 \\times \\text{IQR}\n",
    "> $$\n",
    ">\n",
    "> Values smaller than the lower bound or greater than the upper bound are considered **outliers**.\n",
    ">\n",
    "> Now, define a function that verifies whether a column contains outliers:\n",
    ">\n",
    ">```python\n",
    ">def verify_outliers(df: pd.DataFrame, col: str) -> bool:\n",
    ">    q1 = df[col].quantile(0.25)\n",
    ">    q3 = df[col].quantile(0.75)\n",
    ">    iqr = q3 - q1\n",
    ">    # continue from here\n",
    ">```\n",
    ">\n",
    ">Return a bool from the function and apply it on every `numerical` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "320d3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_outliers(df: pd.DataFrame, col: str) -> bool:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define the lower and upper limits\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Count how many values fall outside the limits\n",
    "    outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    outlier_count = outlier_mask.sum()\n",
    "\n",
    "    # Print summary (optional)\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Lower bound: {lower_bound:.4f}, Upper bound: {upper_bound:.4f}\")\n",
    "    print(f\"Outliers found: {outlier_count}\")\n",
    "\n",
    "    # Return True if at least one outlier exists\n",
    "    return outlier_count > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6cd4980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Attribute2\n",
      "Lower bound: -6.0000, Upper bound: 42.0000\n",
      "Outliers found: 65\n",
      "Outliers detected in Attribute2\n",
      "\n",
      "Column: Attribute5\n",
      "Lower bound: -2270.7500, Upper bound: 7525.2500\n",
      "Outliers found: 79\n",
      "Outliers detected in Attribute5\n",
      "\n",
      "Column: Attribute8\n",
      "Lower bound: -1.0000, Upper bound: 7.0000\n",
      "Outliers found: 0\n",
      "No outliers in Attribute8\n",
      "\n",
      "Column: Attribute11\n",
      "Lower bound: -1.0000, Upper bound: 7.0000\n",
      "Outliers found: 0\n",
      "No outliers in Attribute11\n",
      "\n",
      "Column: Attribute13\n",
      "Lower bound: 6.0000, Upper bound: 62.0000\n",
      "Outliers found: 54\n",
      "Outliers detected in Attribute13\n",
      "\n",
      "Column: Attribute16\n",
      "Lower bound: -0.5000, Upper bound: 3.5000\n",
      "Outliers found: 5\n",
      "Outliers detected in Attribute16\n",
      "\n",
      "Column: Attribute18\n",
      "Lower bound: 1.0000, Upper bound: 1.0000\n",
      "Outliers found: 152\n",
      "Outliers detected in Attribute18\n",
      "\n",
      "Column: Attribute21\n",
      "Lower bound: -6.0000, Upper bound: 42.0000\n",
      "Outliers found: 65\n",
      "Outliers detected in Attribute21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "    if verify_outliers(df, col):\n",
    "        print(f\"Outliers detected in {col}\\n\")\n",
    "    else:\n",
    "        print(f\"No outliers in {col}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8181f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h3>Can we also use the IQR method to remove outliers?</h3></summary>\n",
    "\n",
    "> Yes, the same mathematical rule used to *detect* outliers can also be used\n",
    "> to *remove* them.  \n",
    ">\n",
    "> Once we compute the lower and upper bounds:\n",
    ">\n",
    "> $$\n",
    "> \\text{Lower Bound} = Q1 - 1.5 \\times \\text{IQR}\n",
    "> $$\n",
    "> $$\n",
    "> \\text{Upper Bound} = Q3 + 1.5 \\times \\text{IQR}\n",
    "> $$\n",
    ">\n",
    "> We can simply filter the DataFrame to keep only the values **within these limits**.\n",
    ">\n",
    "> This is known as **IQR-based outlier removal** and is one of the most common\n",
    "> preprocessing techniques in data cleaning, especially for algorithms that are \n",
    "> sensitive to extreme values.\n",
    ">\n",
    "> Example function to *remove* outliers from a column:\n",
    ">\n",
    "> ```python\n",
    "> def remove_outliers_iqr(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    ">     q1 = df[col].quantile(0.25)\n",
    ">     q3 = df[col].quantile(0.75)\n",
    ">     iqr = q3 - q1\n",
    ">\n",
    ">     lower = q1 - 1.5 * iqr\n",
    ">     upper = q3 + 1.5 * iqr\n",
    ">\n",
    ">     return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "> ```\n",
    ">\n",
    "___\n",
    "<div style=\"background-color:#f2f2f2; padding:12px; border-left:4px solid #d9534f; border-radius:4px; margin:10px 0;\">\n",
    "<strong>âš ï¸ NOTE:</strong> REMOVING OUTLIERS IS NOT ALWAYS RECOMMENDED.<br>\n",
    "It depends on the context and whether extreme values are real observations or measurement errors.<br>\n",
    "In credit scoring datasets like this one, outliers may represent important patterns of risk.\n",
    "</div>\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d967e",
   "metadata": {},
   "source": [
    "### Q2.9 Any other problematic column?\n",
    "- Check for dtypes and duplicated information ðŸ˜‰\n",
    "- Convert the columns and drop duplicated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c0d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute12</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute14</th>\n",
       "      <th>Attribute15</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute17</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute19</th>\n",
       "      <th>Attribute20</th>\n",
       "      <th>Attribute21</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>67.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>22.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A122</td>\n",
       "      <td>45.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A124</td>\n",
       "      <td>53.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute1  Attribute2 Attribute3 Attribute4  Attribute5 Attribute6  \\\n",
       "0        A11         6.0        A34        A43      1169.0        A65   \n",
       "1        A12        48.0        A32        A43      5951.0        A61   \n",
       "2        A14        12.0        A34        A46      2096.0        A61   \n",
       "3        A11        42.0        A32        A42      7882.0        A61   \n",
       "4        A11        24.0        A33        A40      4870.0        A61   \n",
       "\n",
       "  Attribute7  Attribute8 Attribute9 Attribute10  Attribute11 Attribute12  \\\n",
       "0        A75         3.0        A93        A101          4.0        A121   \n",
       "1        A73         2.0        A92        A101          2.0        A121   \n",
       "2        A74         2.0        A93        A101          3.0        A121   \n",
       "3        A74         2.0        A93        A103          4.0        A122   \n",
       "4        A73         3.0        A93        A101          4.0        A124   \n",
       "\n",
       "   Attribute13 Attribute14 Attribute15  Attribute16 Attribute17  Attribute18  \\\n",
       "0         67.0        A143        A152          2.0        <NA>          1.0   \n",
       "1         22.0        <NA>        A152          1.0        <NA>          1.0   \n",
       "2         49.0        A143        A152          1.0        A172          2.0   \n",
       "3         45.0        A143        A153          1.0        <NA>          2.0   \n",
       "4         53.0        <NA>        A153          2.0        A173          2.0   \n",
       "\n",
       "  Attribute19 Attribute20  Attribute21 class  \n",
       "0        A192        A201          6.0     1  \n",
       "1        A191        A201         48.0     2  \n",
       "2        A191        A201         12.0     1  \n",
       "3        A191        A201         42.0     1  \n",
       "4        A191        A201         24.0     2  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6320058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated columns by content: ['Attribute21']\n"
     ]
    }
   ],
   "source": [
    "duplicate_cols = df.T[df.T.duplicated()].index.tolist()\n",
    "\n",
    "print(\"Duplicated columns by content:\", duplicate_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "041bfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows found: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute12</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute14</th>\n",
       "      <th>Attribute15</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute17</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute19</th>\n",
       "      <th>Attribute20</th>\n",
       "      <th>Attribute21</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Attribute1, Attribute2, Attribute3, Attribute4, Attribute5, Attribute6, Attribute7, Attribute8, Attribute9, Attribute10, Attribute11, Attribute12, Attribute13, Attribute14, Attribute15, Attribute16, Attribute17, Attribute18, Attribute19, Attribute20, Attribute21, class]\n",
       "Index: []"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets verify for duplicated rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(f\"Duplicated rows found: {duplicate_rows.shape[0]}\")\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602c63c",
   "metadata": {},
   "source": [
    "### Q2.10 Export the dataset to a `csv` file as `cleaned_credit_risk_dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9d2e7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b70e9f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Before we continue with groupby-based exploration, it is important to notice that  \n",
    "many columns in the German Credit dataset contain *coded categorical values* such as:\n",
    "\n",
    "- `A11`, `A12`, `A13`, â€¦\n",
    "- `A30`, `A31`, â€¦\n",
    "- `A40`, `A41`, â€¦\n",
    "- `A171`, `A172`, â€¦\n",
    "\n",
    "These codes make the dataset harder to read and interpret during analysis.\n",
    "\n",
    "> This is extremely common in real datasets:\n",
    "> - data may come encoded for storage efficiency  \n",
    "> - documentation may be separate from the data  \n",
    "> - variables may need mapping tables to become understandable  \n",
    "\n",
    "To make our exploratory analysis clearer â€” and to avoid constantly checking the data dictionary â€”  \n",
    "we will now apply an explicit **mapping** from coded values to descriptive labels.\n",
    "\n",
    "The mappings below were created based on the official dataset documentation provided in:\n",
    "\n",
    "ðŸ”— https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b34bda",
   "metadata": {},
   "source": [
    ">**Install the library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3344bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ucimlrepo in d:\\setups\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in d:\\setups\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in d:\\setups\\anaconda3\\lib\\site-packages (from ucimlrepo) (2025.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\setups\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\setups\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\setups\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\setups\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\setups\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b536d",
   "metadata": {},
   "source": [
    ">**Load the original dataset using the `ucimlrepo` library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3f21f31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 144, 'name': 'Statlog (German Credit Data)', 'repository_url': 'https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data', 'data_url': 'https://archive.ics.uci.edu/static/public/144/data.csv', 'abstract': 'This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1000, 'num_features': 20, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Other', 'Marital Status', 'Age', 'Occupation'], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1994, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5NC77', 'creators': ['Hans Hofmann'], 'intro_paper': None, 'additional_info': {'summary': 'Two datasets are provided.  the original dataset, in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file \"german.data\".   \\r\\n \\r\\nFor algorithms that need numerical attributes, Strathclyde University produced the file \"german.data-numeric\".  This file has been edited and several indicator variables added to make it suitable for algorithms which cannot cope with categorical variables.   Several attributes that are ordered categorical (such as attribute 17) have been coded as integer.    This was the form used by StatLog.\\r\\n\\r\\nThis dataset requires use of a cost matrix (see below)\\r\\n\\r\\n ..... 1        2\\r\\n----------------------------\\r\\n  1   0        1\\r\\n-----------------------\\r\\n  2   5        0\\r\\n\\r\\n(1 = Good,  2 = Bad)\\r\\n\\r\\nThe rows represent the actual classification and the columns the predicted classification.\\r\\n\\r\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Attribute 1:  (qualitative)      \\r\\n Status of existing checking account\\r\\n             A11 :      ... <    0 DM\\r\\n\\t       A12 : 0 <= ... <  200 DM\\r\\n\\t       A13 :      ... >= 200 DM / salary assignments for at least 1 year\\r\\n               A14 : no checking account\\r\\n\\r\\nAttribute 2:  (numerical)\\r\\n\\t      Duration in month\\r\\n\\r\\nAttribute 3:  (qualitative)\\r\\n\\t      Credit history\\r\\n\\t      A30 : no credits taken/ all credits paid back duly\\r\\n              A31 : all credits at this bank paid back duly\\r\\n\\t      A32 : existing credits paid back duly till now\\r\\n              A33 : delay in paying off in the past\\r\\n\\t      A34 : critical account/  other credits existing (not at this bank)\\r\\n\\r\\nAttribute 4:  (qualitative)\\r\\n\\t      Purpose\\r\\n\\t      A40 : car (new)\\r\\n\\t      A41 : car (used)\\r\\n\\t      A42 : furniture/equipment\\r\\n\\t      A43 : radio/television\\r\\n\\t      A44 : domestic appliances\\r\\n\\t      A45 : repairs\\r\\n\\t      A46 : education\\r\\n\\t      A47 : (vacation - does not exist?)\\r\\n\\t      A48 : retraining\\r\\n\\t      A49 : business\\r\\n\\t      A410 : others\\r\\n\\r\\nAttribute 5:  (numerical)\\r\\n\\t      Credit amount\\r\\n\\r\\nAttibute 6:  (qualitative)\\r\\n\\t      Savings account/bonds\\r\\n\\t      A61 :          ... <  100 DM\\r\\n\\t      A62 :   100 <= ... <  500 DM\\r\\n\\t      A63 :   500 <= ... < 1000 DM\\r\\n\\t      A64 :          .. >= 1000 DM\\r\\n              A65 :   unknown/ no savings account\\r\\n\\r\\nAttribute 7:  (qualitative)\\r\\n\\t      Present employment since\\r\\n\\t      A71 : unemployed\\r\\n\\t      A72 :       ... < 1 year\\r\\n\\t      A73 : 1  <= ... < 4 years  \\r\\n\\t      A74 : 4  <= ... < 7 years\\r\\n\\t      A75 :       .. >= 7 years\\r\\n\\r\\nAttribute 8:  (numerical)\\r\\n\\t      Installment rate in percentage of disposable income\\r\\n\\r\\nAttribute 9:  (qualitative)\\r\\n\\t      Personal status and sex\\r\\n\\t      A91 : male   : divorced/separated\\r\\n\\t      A92 : female : divorced/separated/married\\r\\n              A93 : male   : single\\r\\n\\t      A94 : male   : married/widowed\\r\\n\\t      A95 : female : single\\r\\n\\r\\nAttribute 10: (qualitative)\\r\\n\\t      Other debtors / guarantors\\r\\n\\t      A101 : none\\r\\n\\t      A102 : co-applicant\\r\\n\\t      A103 : guarantor\\r\\n\\r\\nAttribute 11: (numerical)\\r\\n\\t      Present residence since\\r\\n\\r\\nAttribute 12: (qualitative)\\r\\n\\t      Property\\r\\n\\t      A121 : real estate\\r\\n\\t      A122 : if not A121 : building society savings agreement/ life insurance\\r\\n              A123 : if not A121/A122 : car or other, not in attribute 6\\r\\n\\t      A124 : unknown / no property\\r\\n\\r\\nAttribute 13: (numerical)\\r\\n\\t      Age in years\\r\\n\\r\\nAttribute 14: (qualitative)\\r\\n\\t      Other installment plans \\r\\n\\t      A141 : bank\\r\\n\\t      A142 : stores\\r\\n\\t      A143 : none\\r\\n\\r\\nAttribute 15: (qualitative)\\r\\n\\t      Housing\\r\\n\\t      A151 : rent\\r\\n\\t      A152 : own\\r\\n\\t      A153 : for free\\r\\n\\r\\nAttribute 16: (numerical)\\r\\n              Number of existing credits at this bank\\r\\n\\r\\nAttribute 17: (qualitative)\\r\\n\\t      Job\\r\\n\\t      A171 : unemployed/ unskilled  - non-resident\\r\\n\\t      A172 : unskilled - resident\\r\\n\\t      A173 : skilled employee / official\\r\\n\\t      A174 : management/ self-employed/\\r\\n\\t\\t     highly qualified employee/ officer\\r\\n\\r\\nAttribute 18: (numerical)\\r\\n\\t      Number of people being liable to provide maintenance for\\r\\n\\r\\nAttribute 19: (qualitative)\\r\\n\\t      Telephone\\r\\n\\t      A191 : none\\r\\n\\t      A192 : yes, registered under the customers name\\r\\n\\r\\nAttribute 20: (qualitative)\\r\\n\\t      foreign worker\\r\\n\\t      A201 : yes\\r\\n\\t      A202 : no\\r\\n', 'citation': None}}\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(statlog_german_credit_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(statlog_german_credit_data.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41eae6",
   "metadata": {},
   "source": [
    ">**Renaming the columns with human-readable names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6c9ad428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>employment_since</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>dependents</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>months</th>\n",
       "      <th>credit_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>67.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>22.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A122</td>\n",
       "      <td>45.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A124</td>\n",
       "      <td>53.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>A153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration_months credit_history purpose  credit_amount  \\\n",
       "0             A11              6.0            A34     A43         1169.0   \n",
       "1             A12             48.0            A32     A43         5951.0   \n",
       "2             A14             12.0            A34     A46         2096.0   \n",
       "3             A11             42.0            A32     A42         7882.0   \n",
       "4             A11             24.0            A33     A40         4870.0   \n",
       "\n",
       "  savings_account employment_since  installment_rate personal_status_sex  \\\n",
       "0             A65              A75               3.0                 A93   \n",
       "1             A61              A73               2.0                 A92   \n",
       "2             A61              A74               2.0                 A93   \n",
       "3             A61              A74               2.0                 A93   \n",
       "4             A61              A73               3.0                 A93   \n",
       "\n",
       "  other_debtors  residence_since property   age other_installment_plans  \\\n",
       "0          A101              4.0     A121  67.0                    A143   \n",
       "1          A101              2.0     A121  22.0                    <NA>   \n",
       "2          A101              3.0     A121  49.0                    A143   \n",
       "3          A103              4.0     A122  45.0                    A143   \n",
       "4          A101              4.0     A124  53.0                    <NA>   \n",
       "\n",
       "  housing  existing_credits   job  dependents telephone foreign_worker  \\\n",
       "0    A152               2.0  <NA>         1.0      A192           A201   \n",
       "1    A152               1.0  <NA>         1.0      A191           A201   \n",
       "2    A152               1.0  A172         2.0      A191           A201   \n",
       "3    A153               1.0  <NA>         2.0      A191           A201   \n",
       "4    A153               2.0  A173         2.0      A191           A201   \n",
       "\n",
       "   months credit_risk  \n",
       "0     6.0           1  \n",
       "1    48.0           2  \n",
       "2    12.0           1  \n",
       "3    42.0           1  \n",
       "4    24.0           2  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {\n",
    "    \"Attribute1\":  \"checking_status\",\n",
    "    \"Attribute2\":  \"duration_months\",\n",
    "    \"Attribute3\":  \"credit_history\",\n",
    "    \"Attribute4\":  \"purpose\",\n",
    "    \"Attribute5\":  \"credit_amount\",\n",
    "    \"Attribute6\":  \"savings_account\",\n",
    "    \"Attribute7\":  \"employment_since\",\n",
    "    \"Attribute8\":  \"installment_rate\",\n",
    "    \"Attribute9\":  \"personal_status_sex\",\n",
    "    \"Attribute10\": \"other_debtors\",\n",
    "    \"Attribute11\": \"residence_since\",\n",
    "    \"Attribute12\": \"property\",\n",
    "    \"Attribute13\": \"age\",\n",
    "    \"Attribute14\": \"other_installment_plans\",\n",
    "    \"Attribute15\": \"housing\",\n",
    "    \"Attribute16\": \"existing_credits\",\n",
    "    \"Attribute17\": \"job\",\n",
    "    \"Attribute18\": \"dependents\",\n",
    "    \"Attribute19\": \"telephone\",\n",
    "    \"Attribute20\": \"foreign_worker\",\n",
    "    \"Attribute21\": \"months\",\n",
    "    \"Attribute22\": \"postal_area\",\n",
    "    \"class\":       \"credit_risk\"\n",
    "    \n",
    "}\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25cf63",
   "metadata": {},
   "source": [
    ">**Run the following block to replace the coded categorical values with human-readable descriptions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "224a9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# SAVE ORIGINAL PERSONAL_STATUS_SEX CODES\n",
    "# (needed later to extract 'sex' and clean personal status)\n",
    "# -----------------------------------------\n",
    "df[\"personal_status_sex_code\"] = df[\"personal_status_sex\"].copy()\n",
    "\n",
    "# -----------------------------------------\n",
    "# MAPPINGS FOR QUALITATIVE VARIABLES\n",
    "# -----------------------------------------\n",
    "\n",
    "map_status = {\n",
    "    \"A11\": \"< 0 DM\",\n",
    "    \"A12\": \"0<=X<200 DM\",\n",
    "    \"A13\": \">=200 DM / salary assignments â‰¥ 1 year\",\n",
    "    \"A14\": \"no checking account\"\n",
    "}\n",
    "\n",
    "map_history = {\n",
    "    \"A30\": \"no credits taken / all paid back duly\",\n",
    "    \"A31\": \"all credits at this bank paid back duly\",\n",
    "    \"A32\": \"existing credits paid back duly till now\",\n",
    "    \"A33\": \"delay in paying off in the past\",\n",
    "    \"A34\": \"critical account / other credits elsewhere\"\n",
    "}\n",
    "\n",
    "map_purpose = {\n",
    "    \"A40\": \"car (new)\",\n",
    "    \"A41\": \"car (used)\",\n",
    "    \"A42\": \"furniture/equipment\",\n",
    "    \"A43\": \"radio/television\",\n",
    "    \"A44\": \"domestic appliances\",\n",
    "    \"A45\": \"repairs\",\n",
    "    \"A46\": \"education\",\n",
    "    # A47 does not exist in the original dataset\n",
    "    \"A48\": \"retraining\",\n",
    "    \"A49\": \"business\",\n",
    "    \"A410\": \"others\"\n",
    "}\n",
    "\n",
    "map_savings = {\n",
    "    \"A61\": \"<100 DM\",\n",
    "    \"A62\": \"100<=X<500 DM\",\n",
    "    \"A63\": \"500<=X<1000 DM\",\n",
    "    \"A64\": \">=1000 DM\",\n",
    "    \"A65\": \"unknown/no savings\"\n",
    "}\n",
    "\n",
    "map_employment = {\n",
    "    \"A71\": \"unemployed\",\n",
    "    \"A72\": \"<1 year\",\n",
    "    \"A73\": \"1â€“4 years\",\n",
    "    \"A74\": \"4â€“7 years\",\n",
    "    \"A75\": \">=7 years\"\n",
    "}\n",
    "\n",
    "# Combined personal status + sex text\n",
    "map_personal_status_sex = {\n",
    "    \"A91\": \"male: divorced/separated\",\n",
    "    \"A92\": \"female: divorced/separated/married\",\n",
    "    \"A93\": \"male: single\",\n",
    "    \"A94\": \"male: married/widowed\",\n",
    "    \"A95\": \"female: single\"\n",
    "}\n",
    "\n",
    "map_debtors = {\n",
    "    \"A101\": \"none\",\n",
    "    \"A102\": \"co-applicant\",\n",
    "    \"A103\": \"guarantor\"\n",
    "}\n",
    "\n",
    "map_property = {\n",
    "    \"A121\": \"real estate\",\n",
    "    \"A122\": \"building society savings/life insurance\",\n",
    "    \"A123\": \"car or other (not in savings)\",\n",
    "    \"A124\": \"unknown/no property\"\n",
    "}\n",
    "\n",
    "map_installment_plans = {\n",
    "    \"A141\": \"bank\",\n",
    "    \"A142\": \"stores\",\n",
    "    \"A143\": \"none\"\n",
    "}\n",
    "\n",
    "map_housing = {\n",
    "    \"A151\": \"rent\",\n",
    "    \"A152\": \"own\",\n",
    "    \"A153\": \"for free\"\n",
    "}\n",
    "\n",
    "map_job = {\n",
    "    \"A171\": \"unemployed/unskilled â€“ non-resident\",\n",
    "    \"A172\": \"unskilled â€“ resident\",\n",
    "    \"A173\": \"skilled employee/official\",\n",
    "    \"A174\": \"management/self-employed/highly qualified\"\n",
    "}\n",
    "\n",
    "map_telephone = {\n",
    "    \"A191\": \"none\",\n",
    "    \"A192\": \"yes, registered\"\n",
    "}\n",
    "\n",
    "map_foreign = {\n",
    "    \"A201\": \"yes\",\n",
    "    \"A202\": \"no\"\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# APPLY MAPPINGS TO THE DATAFRAME\n",
    "# -----------------------------------------\n",
    "\n",
    "df = df.replace({\n",
    "    \"status\": map_status,\n",
    "    \"credit_history\": map_history,\n",
    "    \"purpose\": map_purpose,\n",
    "    \"savings\": map_savings,\n",
    "    \"present_employment\": map_employment,\n",
    "    \"personal_status_sex\": map_personal_status_sex,  # human-readable combined field\n",
    "    \"other_debtors\": map_debtors,\n",
    "    \"property\": map_property,\n",
    "    \"other_installment_plans\": map_installment_plans,\n",
    "    \"housing\": map_housing,\n",
    "    \"job\": map_job,\n",
    "    \"telephone\": map_telephone,\n",
    "    \"foreign_worker\": map_foreign\n",
    "})\n",
    "\n",
    "# -----------------------------------------\n",
    "# SPLIT personal_status_sex INTO 'sex' AND CLEAN 'personal_status'\n",
    "# (using the original codes saved in personal_status_sex_code)\n",
    "# -----------------------------------------\n",
    "\n",
    "# Mapping to extract sex only\n",
    "map_sex = {\n",
    "    \"A91\": \"male\",\n",
    "    \"A92\": \"female\",\n",
    "    \"A93\": \"male\",\n",
    "    \"A94\": \"male\",\n",
    "    \"A95\": \"female\"\n",
    "}\n",
    "\n",
    "# Mapping to extract civil/marital status only\n",
    "map_personal_status_clean = {\n",
    "    \"A91\": \"divorced/separated\",\n",
    "    \"A92\": \"divorced/separated/married\",\n",
    "    \"A93\": \"single\",\n",
    "    \"A94\": \"married/widowed\",\n",
    "    \"A95\": \"single\"\n",
    "}\n",
    "\n",
    "# Create the new 'sex' column\n",
    "df[\"sex\"] = df[\"personal_status_sex_code\"].map(map_sex)\n",
    "\n",
    "# Create a new 'personal_status' column with only civil status\n",
    "df[\"personal_status\"] = df[\"personal_status_sex_code\"].map(map_personal_status_clean)\n",
    "\n",
    "# Drop the temporary code column\n",
    "df.drop(columns=[\"personal_status_sex_code\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b76460",
   "metadata": {},
   "source": [
    "## 3. Introduction to `groupby()` for Exploratory Analysis\n",
    "\n",
    "> Until now, we have used methods such as `value_counts()`, `mean()`, or `describe()`  \n",
    "> to inspect columns individually.\n",
    ">\n",
    "> However, real datasets often have **subgroups** that behave differently, and we may want\n",
    "> to understand how a variable behaves *inside* each subgroup.\n",
    ">\n",
    "> For this, Pandas provides the command:\n",
    ">\n",
    "> `df.groupby(\"column\")`\n",
    ">\n",
    "> which splits the dataset into smaller groups based on the values of one column.\n",
    ">\n",
    "> Each group can then be inspected separately.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Counting Values Inside Groups â€” `.groupby().value_counts()`\n",
    "\n",
    "> This tells us **how a categorical variable behaves inside each subgroup**.\n",
    ">\n",
    ">**Example:**\n",
    ">\n",
    ">```python\n",
    ">   df.groupby(\"housing\")[\"checking_status\"].value_counts()\n",
    ">```\n",
    "\n",
    "### Q3.1. Inspect Categorical Distributions Inside Groups\n",
    "\n",
    "- Using `.groupby('col1')['related_col'].value_counts()`, compute how the column\n",
    "`personal_status` is distributed inside each `credit_risk` group.\n",
    "\n",
    "- Your output should show, **for each value** of `credit_risk`,\n",
    "**the count of each category** in `personal_status`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3d0869b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_risk  personal_status           \n",
       "1            single                        353\n",
       "             divorced/separated/married    179\n",
       "             married/widowed                64\n",
       "             divorced/separated             29\n",
       "2            single                        133\n",
       "             divorced/separated/married     99\n",
       "             married/widowed                25\n",
       "             divorced/separated             17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"credit_risk\")[\"personal_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff653220",
   "metadata": {},
   "source": [
    "### Q3.2 Inspect Categorical Distributions Inside Sub-Groups\n",
    "\n",
    "- Using `.groupby(['col1', 'col2'])['related_col'].value_counts()`, compute how the column\n",
    "`personal_status` is distributed across each `sex` category within each `credit_risk` group.\n",
    "\n",
    "- The output should display, for every value of credit_risk, the count of each category in personal_status, separated by sex.\n",
    "\n",
    ">**Keep in mind that as we add more grouping columns, the resulting output becomes less intuitive to read.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f15cb3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_risk  sex     personal_status           \n",
       "1            female  divorced/separated/married    179\n",
       "             male    single                        353\n",
       "                     married/widowed                64\n",
       "                     divorced/separated             29\n",
       "2            female  divorced/separated/married     99\n",
       "             male    single                        133\n",
       "                     married/widowed                25\n",
       "                     divorced/separated             17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"credit_risk\", \"sex\"])[\"personal_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84356ab2",
   "metadata": {},
   "source": [
    "### Q3.3 Compare the distribution of `housing` Inside each `credit_risk` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ce8d1082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_risk  housing \n",
       "1            own         467\n",
       "             rent        101\n",
       "             for free     60\n",
       "2            own         182\n",
       "             rent         64\n",
       "             for free     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"credit_risk\")[\"housing\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369d3e7",
   "metadata": {},
   "source": [
    "### Q3.4 Which professionals category have the highest average credit amount?\n",
    "\n",
    "- For each `job` category, compute the mean of `credit_amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2e70dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "management/self-employed/highly qualified    5198.668966\n",
       "skilled employee/official                    3000.796265\n",
       "unskilled â€“ resident                         2348.148148\n",
       "unemployed/unskilled â€“ non-resident          2147.400000\n",
       "Name: credit_amount, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"job\")[\"credit_amount\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe6474",
   "metadata": {},
   "source": [
    "### Q3.5. Inspect `age` statistics inside each `credit_risk` group\n",
    "- Compute descriptive statistics (`.describe()`) for the column `age` inside each `credit_risk` group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a23f41c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_risk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664.0</td>\n",
       "      <td>36.951807</td>\n",
       "      <td>17.123122</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294.0</td>\n",
       "      <td>34.210884</td>\n",
       "      <td>15.361061</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std  min   25%   50%   75%    max\n",
       "credit_risk                                                           \n",
       "1            664.0  36.951807  17.123122 -5.0  27.0  33.0  42.0  150.0\n",
       "2            294.0  34.210884  15.361061 -5.0  25.0  31.0  39.0  150.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df.groupby(\"credit_risk\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105bbe0",
   "metadata": {},
   "source": [
    "### Q3.6. Create an `age` **binning column** (`age_group`) to explore group statistics\n",
    "\n",
    "\n",
    ">**Remember that we can create bins using `cut` like:**\n",
    ">\n",
    ">```python\n",
    ">   bins = [0, 25, 40, 60, 120]   # interval limits\n",
    ">   labels = [\"<25\", \"25â€“40\", \"40â€“60\", \"60+\"]  # names of the age groups\n",
    ">\n",
    ">   df[\"age_bin\"] = pd.cut(df[\"col\"], bins=bins, labels=labels)\n",
    ">```\n",
    ">\n",
    ">**Using `qcut` to split into equal `n` parts like:**\n",
    ">\n",
    ">```python\n",
    ">   df[\"age_bin_q\"] = pd.qcut(df[\"col\"], q=n, labels=[\"Q1\", \"Q2\", \"Q3\", ..., \"QN\"])\n",
    ">```\n",
    "\n",
    "- **We want meaningful age groups such as (e.g., `<25`, `25â€“40`, `40â€“60`, `60+`).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "21c16a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "25â€“40    563\n",
       "40â€“60    225\n",
       "<25      144\n",
       "60+       48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 25, 40, 60, 120]  \n",
    "labels = [\"<25\", \"25â€“40\", \"40â€“60\", \"60+\"]  \n",
    "\n",
    "df[\"age_group\"] = pd.cut(df[\"age\"], bins=bins, labels=labels, right=False)\n",
    "df[\"age_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416337f",
   "metadata": {},
   "source": [
    "### Q3.7. Compare credit risk across age groups\n",
    "\n",
    "- Using the `age_group` created in the previous question, analyze how `credit_risk` is distributed inside each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d4b8f5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  credit_risk\n",
       "<25        1               81\n",
       "           2               54\n",
       "25â€“40      1              378\n",
       "           2              163\n",
       "40â€“60      1              157\n",
       "           2               58\n",
       "60+        1               34\n",
       "           2               13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"credit_risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a93da",
   "metadata": {},
   "source": [
    "### Q3.8 Compute the percentage of bad credit risk per age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1b4d9f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_risk\n",
       "1    664\n",
       "2    294\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['credit_risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cd4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "<25      40.000000\n",
       "25â€“40    30.129390\n",
       "40â€“60    26.976744\n",
       "60+      27.659574\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 = Good, 2 = Bad\n",
    "(\n",
    "    df.groupby(\"age_group\", observed=False)[\"credit_risk\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .loc[:, 2] * 100 # we are going to filter for 2 (Bad)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82c54d",
   "metadata": {},
   "source": [
    "### Q3.9 Based on the previous question answer, younger or older customers are more likely to have good or bad credit risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Younger customers (<25)\n",
    "#Usually show a higher percentage of bad credit risk.\n",
    "#Reasons often include lower financial stability, shorter credit history, and higher risk behavior.\n",
    "\n",
    "# Middle-aged customers (25â€“40, 40â€“60)\n",
    "#Typically have the lowest percentage of bad credit risk.\n",
    "#This group tends to have stable employment, higher income, and more established credit history.\n",
    "\n",
    "# Older customers (60+)\n",
    "#Risk may increase slightly again, but usually not as high as the youngest group.\n",
    "#This can depend on retirement status and fixed-income constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c38aa",
   "metadata": {},
   "source": [
    "### Q3.10 Compare the average credit amount across age Groups\n",
    "\n",
    "- Compute the **mean** value of `credit_amount` for each age group.\n",
    "- Which age group tends to request the highest credit amounts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b328f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "60+      3373.312500\n",
       "40â€“60    3357.480000\n",
       "25â€“40    3225.532860\n",
       "<25      2707.298611\n",
       "Name: credit_amount, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"credit_amount\"].mean().sort_values(ascending=False)\n",
    "# 60+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9d4b7",
   "metadata": {},
   "source": [
    "### Q3.11 Compare Employment Duration Across Age Groups\n",
    "\n",
    "- Compute the count of each `employment_since` category inside each `age_group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8fe12b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  employment_since\n",
       "<25        A73                  52\n",
       "           A72                  43\n",
       "           A74                  24\n",
       "           A71                   8\n",
       "           A75                   7\n",
       "25â€“40      A73                 199\n",
       "           A74                 108\n",
       "           A75                 102\n",
       "           A72                  98\n",
       "           A71                  26\n",
       "40â€“60      A75                 104\n",
       "           A73                  54\n",
       "           A74                  23\n",
       "           A72                  22\n",
       "           A71                  15\n",
       "60+        A75                  23\n",
       "           A73                  11\n",
       "           A71                   8\n",
       "           A74                   4\n",
       "           A72                   0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"employment_since\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15198a6b",
   "metadata": {},
   "source": [
    "### Q3.12 Explore Purpose of Credit Within Age Groups\n",
    "\n",
    "- For each `age_group`, compute how many people requested credit for each type of `purpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "20ad446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  purpose            \n",
       "<25        radio/television        41\n",
       "           furniture/equipment     39\n",
       "           car (new)               25\n",
       "           car (used)              14\n",
       "           business                 7\n",
       "           education                6\n",
       "           domestic appliances      4\n",
       "           repairs                  4\n",
       "           retraining               1\n",
       "           others                   0\n",
       "25â€“40      radio/television       157\n",
       "           car (new)              124\n",
       "           furniture/equipment     87\n",
       "           business                64\n",
       "           car (used)              52\n",
       "           education               22\n",
       "           repairs                  9\n",
       "           others                   6\n",
       "           domestic appliances      5\n",
       "           retraining               5\n",
       "40â€“60      radio/television        58\n",
       "           car (new)               54\n",
       "           furniture/equipment     35\n",
       "           car (used)              25\n",
       "           education               16\n",
       "           business                13\n",
       "           others                   5\n",
       "           repairs                  5\n",
       "           domestic appliances      2\n",
       "           retraining               2\n",
       "60+        car (new)               15\n",
       "           radio/television         9\n",
       "           car (used)               7\n",
       "           business                 6\n",
       "           education                4\n",
       "           repairs                  3\n",
       "           furniture/equipment      2\n",
       "           domestic appliances      1\n",
       "           others                   1\n",
       "           retraining               0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"purpose\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93817bbf",
   "metadata": {},
   "source": [
    "### Q3.13 Number of Existing Credits by Age Group\n",
    "- determine which age group tends to have more existing credit lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "53670733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "60+      1.562500\n",
       "40â€“60    1.417778\n",
       "25â€“40    1.390764\n",
       "<25      1.201389\n",
       "Name: existing_credits, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"existing_credits\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb69e2",
   "metadata": {},
   "source": [
    "### Q3.14 Cross-Analyze Age Groups and Housing\n",
    "\n",
    "- For each age_group, compute how many people fall into each housing category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8c3f7cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>housing</th>\n",
       "      <th>for free</th>\n",
       "      <th>own</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;25</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25â€“40</th>\n",
       "      <td>43</td>\n",
       "      <td>421</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40â€“60</th>\n",
       "      <td>39</td>\n",
       "      <td>143</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60+</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "housing    for free  own  rent\n",
       "age_group                     \n",
       "<25               5   67    65\n",
       "25â€“40            43  421    74\n",
       "40â€“60            39  143    27\n",
       "60+              14   31     3"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"housing\"].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0d146",
   "metadata": {},
   "source": [
    "## 3.2 Aggregating Multiple Statistics with `.agg()`\n",
    "\n",
    "> Until now, we have computed one summary statistic at a time:\n",
    ">\n",
    "> - `.mean()`\n",
    "> - `.size()`\n",
    "> - `.value_counts()`\n",
    "> - `.describe()`\n",
    ">\n",
    "> These methods are useful, but they only compute **one metric at a time**.\n",
    ">\n",
    "> The real power of `groupby()` comes when we want to calculate **several statistics at once**,  \n",
    "> either for:\n",
    ">\n",
    "> - the **same column**, or  \n",
    "> - **multiple columns** with different metrics.\n",
    ">\n",
    "> For this, Pandas provides the method:\n",
    ">\n",
    "> ```python\n",
    "> df.groupby(\"column\").agg({...})\n",
    "> ```\n",
    ">\n",
    "> which allows us to define exactly **which statistics** to compute.\n",
    "---\n",
    ">\n",
    ">**Example 1 â€” Multiple Statistics for One Column**\n",
    ">\n",
    ">```python\n",
    ">   df.groupby(\"age_group\")[\"credit_amount\"].agg([\"mean\", \"median\", \"max\"])\n",
    ">```\n",
    "___\n",
    ">**Example 2 â€” Different Statistics for Different Columns**\n",
    ">```python\n",
    ">   df.groupby(\"age_bin\").agg({\n",
    ">    \"credit_amount\": [\"mean\", \"std\"],\n",
    ">    \"duration_months\": [\"mean\", \"max\"]\n",
    ">})\n",
    ">```\n",
    "___\n",
    "> **Example 3 â€” Using Custom Functions Inside `.agg()`**\n",
    ">\n",
    "> You can also define your own functions and use them directly inside `.agg()`.\n",
    ">\n",
    "> This is extremely useful when the standard statistics (`mean`, `median`, etc.) are not enough for your analysis.\n",
    ">\n",
    "> ```python\n",
    "> # Custom function: range = max - min\n",
    "> def value_range(series):\n",
    ">     return series.max() - series.min()\n",
    ">\n",
    "> df.groupby(\"age_group\")[\"credit_amount\"].agg([\n",
    ">     \"mean\",\n",
    ">     \"median\",\n",
    ">     value_range,     # custom function\n",
    "> ])\n",
    "> ```\n",
    ">\n",
    "> **This will return a table containing:**\n",
    "> - the mean  \n",
    "> - the median  \n",
    "> - and your custom-defined \"range\" metric  \n",
    ">\n",
    "> computed separately **for each age group**.\n",
    "___\n",
    ">**This approach is very common because it allows you to summarize multiple variables at once, grouped by a meaningful category**\n",
    "\n",
    "### Q3.15. Multiple Statistics for `credit_amount` per age group\n",
    "\n",
    "- Using `.groupby(\"age_group\")` and `.agg()`, compute the following statistics for `credit_amount` inside each `age_group`:\n",
    "\n",
    "    - mean  \n",
    "    - median\n",
    "    - maximum value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "76638874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;25</th>\n",
       "      <td>2707.298611</td>\n",
       "      <td>2090.5</td>\n",
       "      <td>15672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25â€“40</th>\n",
       "      <td>3225.532860</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>18424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40â€“60</th>\n",
       "      <td>3357.480000</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>15945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60+</th>\n",
       "      <td>3373.312500</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>14896.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean  median      max\n",
       "age_group                              \n",
       "<25        2707.298611  2090.5  15672.0\n",
       "25â€“40      3225.532860  2320.0  18424.0\n",
       "40â€“60      3357.480000  2320.0  15945.0\n",
       "60+        3373.312500  2283.0  14896.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"credit_amount\"].agg([\"mean\", \"median\", \"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a9107",
   "metadata": {},
   "source": [
    "### Q3.16. Aggregate Two Numerical Columns at Once\n",
    "\n",
    "- Using .groupby(\"age_group\"), compute:\n",
    "\n",
    "    - mean and standard deviation of credit_amount\n",
    "\n",
    "    - mean and max of duration_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "74f0daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">credit_amount</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;25</th>\n",
       "      <td>2707.298611</td>\n",
       "      <td>2398.726854</td>\n",
       "      <td>20.291667</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25â€“40</th>\n",
       "      <td>3225.532860</td>\n",
       "      <td>2618.308932</td>\n",
       "      <td>21.280639</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40â€“60</th>\n",
       "      <td>3357.480000</td>\n",
       "      <td>2873.304345</td>\n",
       "      <td>20.288889</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60+</th>\n",
       "      <td>3373.312500</td>\n",
       "      <td>3416.232840</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          credit_amount              duration_months      \n",
       "                   mean          std            mean   max\n",
       "age_group                                                 \n",
       "<25         2707.298611  2398.726854       20.291667  72.0\n",
       "25â€“40       3225.532860  2618.308932       21.280639  60.0\n",
       "40â€“60       3357.480000  2873.304345       20.288889  60.0\n",
       "60+         3373.312500  3416.232840       19.166667  60.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False).agg({\n",
    "    \"credit_amount\": [\"mean\", \"std\"],\n",
    "    \"duration_months\": [\"mean\", \"max\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6606d",
   "metadata": {},
   "source": [
    "### Q3.17 Define your own function that computes the range of a numeric variable.\n",
    "- Using `.groupby(\"age_group\")[\"credit_amount\"].agg([...])`, compute:\n",
    "\n",
    "    - mean\n",
    "    - median\n",
    "    - your custom range function\n",
    "\n",
    ">**Example**\n",
    ">```python\n",
    ">   # Custom function: range = max - min\n",
    ">   def value_range(series: pd.Series):\n",
    ">       # your code here\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d0676476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function: range = max - min\n",
    "def value_range(series: pd.Series):\n",
    "    return series.max() - series.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "50d33965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;25</th>\n",
       "      <td>2707.298611</td>\n",
       "      <td>2090.5</td>\n",
       "      <td>15396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25â€“40</th>\n",
       "      <td>3225.532860</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>18081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40â€“60</th>\n",
       "      <td>3357.480000</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>15607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60+</th>\n",
       "      <td>3373.312500</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>14325.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean  median  value_range\n",
       "age_group                                  \n",
       "<25        2707.298611  2090.5      15396.0\n",
       "25â€“40      3225.532860  2320.0      18081.0\n",
       "40â€“60      3357.480000  2320.0      15607.0\n",
       "60+        3373.312500  2283.0      14325.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"age_group\", observed=False)[\"credit_amount\"].agg([\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "    value_range\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a495aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your tears here ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your tears here ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45048b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your tears here ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756e451",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
