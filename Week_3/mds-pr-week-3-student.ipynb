{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "981f94d4",
      "metadata": {
        "id": "981f94d4"
      },
      "source": [
        "# Week 3 - Data Wrangling\n",
        "\n",
        "In this notebook we will practice data cleaning and wrangling using a *messy* version of the Titanic dataset.\n",
        "\n",
        "Topics covered:\n",
        "- Inspecting data\n",
        "- Preprocessing\n",
        "    - Categorical x Numerical Data\n",
        "    - Fixing column types\n",
        "    - Standardizing Categorical Values\n",
        "    - Missing values (Identifying and Imputation)\n",
        "- Feature Engineering\n",
        "- Exporting and Loading Cleaned Data\n",
        "\n",
        "### SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8e456f",
      "metadata": {
        "id": "2d8e456f"
      },
      "outputs": [],
      "source": [
        "# if you any of those\n",
        "#!pip install pandas numpy seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c21761",
      "metadata": {
        "id": "09c21761"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "887cd0a9",
      "metadata": {
        "id": "887cd0a9"
      },
      "source": [
        "##  Dataset\n",
        "\n",
        "In this section, we will work with real-world datasets to apply the concepts we have learned so far.\n",
        "\n",
        "Let's load a sample dataset using Pandas.\n",
        "\n",
        "We are going to use the popular `Titanic` dataset, which contains information about passengers on the Titanic, including whether they survived the disaster.\n",
        "\n",
        "**Data dictionary**\n",
        "\n",
        "| Column | Description |\n",
        "|---|---|\n",
        "| PassengerId | Unique ID : T (Titanic) + ticket class + year + port + incremental ID per class.\n",
        "| Survived | 0 = No, 1 = Yes |\n",
        "| Pclass | Ticket class (1, 2, 3) |\n",
        "| Name | Passenger name |\n",
        "| Sex | Gender |\n",
        "| Age | Age in years |\n",
        "| SibSp | Siblings/spouses aboard |\n",
        "| Parch | Parents/children aboard |\n",
        "| Fare | Ticket fare |\n",
        "| Deck | Deck letter |\n",
        "| Embarked | Port of embarkation (C/Q/S)|\n",
        "\n",
        "## 1. Inspecting the dataset\n",
        "\n",
        "### Load the Titanic dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3803f08b",
      "metadata": {
        "id": "3803f08b"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cade3f8a",
      "metadata": {
        "id": "cade3f8a"
      },
      "source": [
        "Before anything, we must load the dataset correctly\n",
        "\n",
        "Manually inspect the dataset file or run the command `!head file_name.csv` or `!cat file_name.csv` - **head** might not work in windows OS üòä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a7da04",
      "metadata": {
        "id": "a1a7da04"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c247e1f",
      "metadata": {
        "id": "3c247e1f"
      },
      "source": [
        "Now try again using `sep`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a503df8",
      "metadata": {
        "id": "9a503df8"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646d740b",
      "metadata": {
        "id": "646d740b"
      },
      "source": [
        "**It seems that someone saved the index by mistake... Lets get rid of it!**\n",
        "\n",
        "### Q.1.1 Drop the unnamed column.\n",
        "- Use `df.drop(columns=['col_name'], inplace=True)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28593762",
      "metadata": {
        "id": "28593762"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f80d189",
      "metadata": {
        "id": "8f80d189"
      },
      "source": [
        "### Q.1.2 How many rows and columns there is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53703d3",
      "metadata": {
        "id": "c53703d3"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a0373d",
      "metadata": {
        "id": "d0a0373d"
      },
      "source": [
        "### Q.1.3 Check of each column data type\n",
        "\n",
        "- Is every column data type the most appropriate for it?\n",
        "- Are there any column with null/missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b16cd03",
      "metadata": {
        "id": "7b16cd03"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b9152f",
      "metadata": {
        "id": "e7b9152f"
      },
      "source": [
        "### Q.1.4 Verify descritive statistics\n",
        "- All numeric columns are being displayed?\n",
        "- Those descritive statistcs are meaningfull for every column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c2d4ec",
      "metadata": {
        "id": "c2c2d4ec"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d81bc5e",
      "metadata": {
        "id": "1d81bc5e"
      },
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "Now that we have at least some information about the dataset, it is more than obvious that there are many problems.\n",
        "\n",
        "Let's preprocess this dataset to make it more viable and clean for future analysis.\n",
        "\n",
        "### Q.2.1 First of all, the documentation provided a column name that does not exist.\n",
        "- Identify and `rename` it:\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e65fe4",
      "metadata": {
        "id": "18e65fe4"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e27140",
      "metadata": {
        "id": "c7e27140"
      },
      "source": [
        "<details>\n",
        "<summary style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; cursor: pointer;\">\n",
        "    <h2 style=\"display: inline;\">\n",
        "        Understanding Numerical vs. Categorical Data\n",
        "        <span style=\"color: red; font-size: 0.8em;\">(click to expand/collapse)</span>\n",
        "    </h2>\n",
        "</summary>\n",
        "\n",
        "It is important to understand **what type of data each column represents**.  \n",
        "Choosing the **correct type** improves **memory usage**, **speeds up operations**, and makes **analysis more reliable**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Numerical Data**\n",
        "\n",
        "These are values that represent quantities and support mathematical operations.\n",
        "\n",
        "Examples:\n",
        "- Age (`22`, `45.0`)\n",
        "- Fare (`71.283`, `15.50`)\n",
        "- Number of siblings (`3`, `0`)\n",
        "- Any measured or counted quantity\n",
        "\n",
        "Two main subtypes:\n",
        "- **int** ‚Üí whole numbers (0, 1, 2‚Ä¶)\n",
        "- **float** ‚Üí decimal numbers (0.0, 3.14‚Ä¶)\n",
        "\n",
        "Numerical columns allow:\n",
        "- statistics (mean, median, std)\n",
        "- plotting histograms\n",
        "- mathematical operations\n",
        "- machine learning models\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Categorical Data**\n",
        "\n",
        "These represent **labels**, **groups**, or **categories**, not quantities.\n",
        "\n",
        "Examples:\n",
        "- Sex (`\"male\"`, `\"female\"`)\n",
        "- Embarkation port (`\"C\"`, `\"Q\"`, `\"S\"`)\n",
        "- Passenger class (`\"First\"`, `\"Second\"`, `\"Third\"`)\n",
        "- Deck (`\"A\"`, `\"B\"`, `\"Unknown\"`)\n",
        "\n",
        "Types commonly used:\n",
        "- **string (object)** ‚Üí free text labels  \n",
        "- **category** ‚Üí optimized categorical labels (recommended)\n",
        "\n",
        "Categorical columns allow:\n",
        "- grouping (`df.groupby(\"sex\")`)\n",
        "- value counts\n",
        "- filtering\n",
        "- faster processing when stored as `category`\n",
        "\n",
        "---\n",
        "\n",
        "### **Why this distinction matters**\n",
        "\n",
        "If a column is stored with the wrong dtype:\n",
        "\n",
        "- A numeric column stored as string **cannot be computed**:  \n",
        "  `\"45\" + \"10\"` ‚Üí `\"4510\"` (string concatenation!)\n",
        "- A categorical column stored as numbers **breaks meaning**\n",
        "- Machine learning pipelines **fail or behave poorly**\n",
        "- Missing values become difficult to detect and fix\n",
        "- Memory usage increases (especially with text)\n",
        "\n",
        "So the first step in Data Wrangling is:\n",
        "\n",
        "üëâ **Identify** whether each column is numerical or categorical  \n",
        "üëâ **Fix** the dtype accordingly\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34eb9992",
      "metadata": {
        "id": "34eb9992"
      },
      "source": [
        "## Fixing Column Types\n",
        "\n",
        "Datasets often contain columns stored with the wrong data type.  \n",
        "This usually happens when values are mixed (e.g., numbers + text), when the file was exported incorrectly, or when data is collected from multiple sources.\n",
        "\n",
        "Working with incorrect types can break calculations, comparisons, plots, or machine-learning pipelines.  \n",
        "So the first step is to **inspect** and **fix** them.\n",
        "\n",
        "**Common strategies for fixing the column types are:**\n",
        "\n",
        "___\n",
        "**Direct convertion:**\n",
        "If you know that the column will be able to be directly converted\n",
        "```python\n",
        "df['column_name'] = df['column_name'].astype(dtype)\n",
        "```\n",
        "___\n",
        "**1. Convert a column to numeric**\n",
        "\n",
        "Use when the column **should be a number**, but contains strings, symbols, or inconsistent formatting.\n",
        "\n",
        "```python\n",
        "df[\"column_name\"] = pd.to_numeric(df[\"column_name\"], errors=\"coerce\")\n",
        "```\n",
        "`errors=\"coerce\"` converts invalid values into **NaN**, which can later be imputed.\n",
        "___\n",
        "\n",
        "**2. Clean and convert a column that contains units or extra text**\n",
        "\n",
        "Useful for columns like \"100 USD\", \"45 years\", \"200 km\".\n",
        "\n",
        "```python\n",
        "df[\"column_name\"] = (\n",
        "    df[\"column_name\"]\n",
        "        .astype(str)\n",
        "        .str.replace(\" USD\", \"\", regex=False)\n",
        ")\n",
        "\n",
        "# now casting to numeric dtype\n",
        "df[\"column_name\"] = pd.to_numeric(df[\"column_name\"], errors=\"coerce\")\n",
        "```\n",
        "___\n",
        "**3. Convert a column to string (categorical text)**\n",
        "\n",
        "Use when the column should represent labels, not numbers.\n",
        "\n",
        "```python\n",
        "df[\"column_name\"] = df[\"column_name\"].astype(str)\n",
        "```\n",
        "\n",
        "**4. Convert a column to category (optional optimization)**\n",
        "\n",
        "Useful for columns with repeated labels (e.g., \"male\", \"female\", \"unknown\").\n",
        "\n",
        "```python\n",
        "df[\"column_name\"] = df[\"column_name\"].astype(\"category\")\n",
        "```\n",
        "___\n",
        "**5. Convert a column to datetime**\n",
        "\n",
        "For dates like \"2020-01-05\" or \"05/01/2020\".\n",
        "```python\n",
        "df[\"column_name\"] = pd.to_datetime(df[\"column_name\"], errors=\"coerce\")\n",
        "```\n",
        "___\n",
        "\n",
        "**After fixing all types, it is good practice to check the result:**\n",
        "\n",
        "- `.info()`\n",
        "- `.dtypes`\n",
        "\n",
        "### Q 2.2 Inspect each column, decide the most appropriate `dtype` and `fix` it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808cece3",
      "metadata": {
        "id": "808cece3"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd1d4512",
      "metadata": {
        "id": "cd1d4512"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbdd4945",
      "metadata": {
        "id": "dbdd4945"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "385b53ce",
      "metadata": {
        "id": "385b53ce"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8989a1",
      "metadata": {
        "id": "fb8989a1"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef8bde3",
      "metadata": {
        "id": "0ef8bde3"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8748b73",
      "metadata": {
        "id": "f8748b73"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d2a60b",
      "metadata": {
        "id": "73d2a60b"
      },
      "source": [
        "## Standardizing Categorical Values\n",
        "\n",
        "Sometimes you may also find inconsistent or incorrect labels in categorical columns.  \n",
        "For example, the same category may appear in multiple formats:\n",
        "\n",
        "- \"female\", \"Female\", \"F\", \"f\"\n",
        "- \"male\", \"Male\", \"M\", \"m\"\n",
        "\n",
        "These inconsistencies make analysis, filtering, and grouping unreliable.  \n",
        "To fix this, we **standardize** all categorical values into a consistent format.\n",
        "\n",
        "---\n",
        "\n",
        "**1. Convert everything to lowercase**\n",
        "\n",
        "This removes differences like \"Female\" vs \"female\".\n",
        "\n",
        "```python\n",
        "df[\"column_name\"] = df[\"column_name\"].astype(str).str.lower()\n",
        "```\n",
        "---\n",
        "\n",
        "**2. If there are many variations, a `mapping dictionary` might help:**\n",
        "\n",
        "```python\n",
        "mapping = {\n",
        "    \"female\": \"female\",\n",
        "    \"f\": \"female\",\n",
        "    \"woman\": \"female\",\n",
        "    \"male\": \"male\",\n",
        "    \"m\": \"male\",\n",
        "    \"man\": \"male\"\n",
        "}\n",
        "\n",
        "df[\"column_name\"] = df[\"column_name\"].replace(mapping)\n",
        "```\n",
        "___\n",
        "**Tips:**\n",
        "\n",
        "- Verify the frequencies of `categorical columns`\n",
        "```python\n",
        "df[\"column_name\"].value_counts()\n",
        "```\n",
        "- Converting to `category` offers optimization in terms of memory footprint, comparinson speed and interpretability\n",
        "```python\n",
        "df[\"column_name\"] = df[\"column_name\"].astype(\"category\")\n",
        "```\n",
        "\n",
        "### Q.2.3 Verify if any categorical column needs to be standardized\n",
        "- Inspect columns of dtype `category`, `object`, `bool`, `int`\n",
        "- Inspect using `df['column'].values_count()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fad9114",
      "metadata": {
        "id": "2fad9114"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fcfad3d",
      "metadata": {
        "id": "0fcfad3d"
      },
      "source": [
        "## Missing values\n",
        "\n",
        "Most real-world datasets contain missing or inconsistent values.\n",
        "\n",
        "We must decide how to handle them. The main strategies are:\n",
        "\n",
        "___\n",
        "**1. Remove rows with missing values**\n",
        "\n",
        "Useful when:\n",
        "\n",
        "Only a few rows contain missing values.\n",
        "\n",
        "Removing them does not distort the dataset.\n",
        "\n",
        "```python\n",
        "df_clean = df.dropna()\n",
        "```\n",
        "___\n",
        "**2. Remove columns with too many missing values**\n",
        "\n",
        "Useful when:\n",
        "\n",
        "A column is mostly empty (e.g., >80% missing maybe even less threshold)\n",
        "\n",
        "The column is not essential for the analysis\n",
        "\n",
        "```python\n",
        "df_clean = df.drop(columns=[\"column_name\"])\n",
        "```\n",
        "___\n",
        "**3. Impute missing values (numeric columns)**\n",
        "\n",
        "Common inputs:\n",
        "\n",
        "- Mean\n",
        "\n",
        "- Median (more robust to outliers)\n",
        "\n",
        "- Constant value\n",
        "\n",
        "```python\n",
        "# mean\n",
        "df[\"column_name\"] = df[\"column_name\"].fillna(df[\"column_name\"].mean())\n",
        "\n",
        "# median\n",
        "df[\"column_name\"] = df[\"column_name\"].fillna(df[\"column_name\"].median())\n",
        "\n",
        "# constant value\n",
        "df[\"column_name\"] = df[\"column_name\"].fillna(1)\n",
        "```\n",
        "___\n",
        "**4. Impute missing values (categorical columns)**\n",
        "\n",
        "Typical strategies:\n",
        "\n",
        "Replace with the most frequent category (mode)\n",
        "\n",
        "Replace with a special label such as \"Unknown\"\n",
        "\n",
        "```python\n",
        "# mode\n",
        "df[\"column_name\"] = df[\"column_name\"].fillna(df[\"column_name\"].mode()[0])\n",
        "\n",
        "# special label\n",
        "df[\"column_name\"] = df[\"column_name\"].fillna(\"Unknown\")\n",
        "```\n",
        "___\n",
        "**There are more advanced methods of imputation but those above cover most of the problems that you might have initially.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8c861e",
      "metadata": {
        "id": "1e8c861e"
      },
      "source": [
        "### Q.2.4 Check for missing values in every column:\n",
        "- Try to obtain a sum of missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4357ff",
      "metadata": {
        "id": "4b4357ff"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa34858",
      "metadata": {
        "id": "dfa34858"
      },
      "source": [
        "### Q.2.5 Which column is the most problematic in terms of missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7db750d",
      "metadata": {
        "id": "b7db750d"
      },
      "outputs": [],
      "source": [
        "# your answer here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c643f9b",
      "metadata": {
        "id": "0c643f9b"
      },
      "source": [
        "### Q.2.6 Let's find out the percentage of missing values in the most problematic column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019b8971",
      "metadata": {
        "id": "019b8971"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2459f1e5",
      "metadata": {
        "id": "2459f1e5"
      },
      "source": [
        "### Q.2.7 Define a function that will check for missing values in percentage each column that you provide as a param.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "def percentage_missing_values(df: pd.DataFrame, col: str) -> float:\n",
        "\n",
        "    # your code here\n",
        "    \n",
        "    return percentage_of_missing\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede344a5",
      "metadata": {
        "id": "ede344a5"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8738d4",
      "metadata": {
        "id": "bd8738d4"
      },
      "source": [
        "### Q 2.8. Impute missing values for each column that requires cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9ff275",
      "metadata": {
        "id": "2e9ff275"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df5c732",
      "metadata": {
        "id": "2df5c732"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d644b6af",
      "metadata": {
        "id": "d644b6af"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eda5a47",
      "metadata": {
        "id": "0eda5a47"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd6f36f",
      "metadata": {
        "id": "fdd6f36f"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffb76a4",
      "metadata": {
        "id": "7ffb76a4"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422bfa87",
      "metadata": {
        "id": "422bfa87"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7032fa",
      "metadata": {
        "id": "6c7032fa"
      },
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Now that the dataset is clean, with corrected data types, standardized categorical values, and missing values imputed, we can begin improving the dataset by **creating new features**.\n",
        "\n",
        "Feature Engineering helps models extract more meaningful patterns by transforming the raw data into something more informative and more useful for analysis or machine learning.\n",
        "\n",
        "---\n",
        ">**1.Mathematical combinations**\n",
        ">Create new features by combining existing numeric features.\n",
        "\n",
        ">**Example: family size**\n",
        ">```python\n",
        ">df[\"family_size\"] = df[\"sibsp\"] + df[\"parch\"] + 1\n",
        ">```\n",
        "---\n",
        ">**2. Binarizing or grouping categories**\n",
        ">Transform categories into simpler or grouped labels.\n",
        "\n",
        ">**Example: traveling alone vs not**\n",
        ">```python\n",
        ">df[\"is_alone\"] = (df[\"family_size\"] == 1)\n",
        ">```\n",
        "---\n",
        ">**3. Extracting information from existing columns**\n",
        "\n",
        ">**Example: title extracted from the passenger name**\n",
        ">```python\n",
        ">df[\"title\"] = df[\"name\"].str.extract(r\",\\s*([^\\.]*)\\.\", expand=False)\n",
        ">df[\"title\"] = df[\"title\"].str.strip().str.lower()\n",
        ">```\n",
        "---\n",
        ">**4. Discretization (binning)**\n",
        ">Convert continuous variables into intervals.\n",
        "\n",
        ">**Example using `cut`:**\n",
        ">```python\n",
        ">df[\"age_group\"] = pd.qcut(\n",
        ">    df[\"age\"],\n",
        ">    bins=[0, 12, 18, 35, 60, 100],\n",
        ">    labels=[\"child\", \"teen\", \"young_adult\", \"adult\", \"senior\"]\n",
        ">)\n",
        ">```\n",
        ">**-  `pd.cut` will consider intervals as `( ]`**\n",
        ">**- `open on left (exclusive)` and `closed on right (inclusive)`**\n",
        "\n",
        ">**Example using `qcut` (data will be split in equal parts)**\n",
        ">```python\n",
        ">df[\"age_group\"] = pd.cut(\n",
        ">    df[\"age\"],\n",
        ">    q=5,\n",
        ">    labels=[\"child\", \"teen\", \"young_adult\", \"adult\", \"senior\"]\n",
        ">)\n",
        ">```\n",
        "---\n",
        ">**5. Encoding boolean or numeric signals**\n",
        "\n",
        ">**Example: indicator for high fare**\n",
        ">```python\n",
        ">df[\"high_fare\"] = df[\"fare\"] > df[\"fare\"].median()\n",
        ">```\n",
        "---\n",
        ">**6. Interaction features**\n",
        ">Features created by combining multiple existing ones.\n",
        "\n",
        ">**Example: price paid per person**\n",
        ">```python\n",
        ">df[\"fare_per_person\"] = df[\"fare\"] / df[\"family_size\"]\n",
        ">```\n",
        "---\n",
        "**Example Creating feature set**\n",
        "\n",
        "```python\n",
        "df[\"family_size\"] = df[\"sibsp\"] + df[\"parch\"] + 1\n",
        "df[\"is_alone\"] = (df[\"family_size\"] == 1)\n",
        "\n",
        "df[\"title\"] = df[\"name\"].str.extract(r\",\\s*([^\\.]*)\\.\", expand=False)\n",
        "df[\"title\"] = df[\"title\"].str.strip().str.lower()\n",
        "\n",
        "df[\"age_group\"] = pd.cut(\n",
        "    df[\"age\"],\n",
        "    bins=[0, 12, 18, 35, 60, 100],\n",
        "    labels=[\"child\", \"teen\", \"young_adult\", \"adult\", \"senior\"]\n",
        ")\n",
        "\n",
        "df[\"high_fare\"] = df[\"fare\"] > df[\"fare\"].median()\n",
        "df[\"fare_per_person\"] = df[\"fare\"] / df[\"family_size\"]\n",
        "\n",
        "df.head()\n",
        "```\n",
        "---\n",
        "### Q 3.1. Create a new column called `is_child` that is `True` when **age < 12**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67b9576",
      "metadata": {
        "id": "b67b9576"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a672c86",
      "metadata": {
        "id": "4a672c86"
      },
      "source": [
        "### **Q 3.2.** Create a column `family_size` based on sibsp e parch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387d65e5",
      "metadata": {
        "id": "387d65e5"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c88ef0b4",
      "metadata": {
        "id": "c88ef0b4"
      },
      "source": [
        "### Q 3.3. Create a `class` column based on the `Ticket Class`.\n",
        "- **1 -> First**\n",
        "- **2 -> Second**\n",
        "- **3 -> Third**\n",
        "\n",
        "- **Set the `dtype` of this column to `category`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df813db3",
      "metadata": {
        "id": "df813db3"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e200b4e",
      "metadata": {
        "id": "0e200b4e"
      },
      "source": [
        "### Q.3.4. Create a `embarked` column based on the Port where the passenger embarked.\n",
        "- **Use the initials as the category value.**\n",
        "- **Set the `dtype` of this column to `category`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecdb5c94",
      "metadata": {
        "id": "ecdb5c94"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c403df3",
      "metadata": {
        "id": "3c403df3"
      },
      "source": [
        "### Q 3.5. Create a `fare_bin` column by splitting fare into 4 quantiles using `pd.qcut`.\n",
        "- use `labels` as a list of `'Low', 'Medium', 'High', 'Very High'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79f7d55",
      "metadata": {
        "id": "e79f7d55"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8551f5e6",
      "metadata": {
        "id": "8551f5e6"
      },
      "source": [
        "### Q 3.6. Create a column `age_fare_ratio` equal to `age / fare`, and comment on whether this feature makes sense.\n",
        "- be careful about zero-division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef27528",
      "metadata": {
        "id": "3ef27528"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5427c7d",
      "metadata": {
        "id": "c5427c7d"
      },
      "source": [
        "### Q 3.7. Create `age_group` **(you decide the bins and labels)** and count how many passengers exist in each `age_group`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5461b582",
      "metadata": {
        "id": "5461b582"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68874d25",
      "metadata": {
        "id": "68874d25"
      },
      "source": [
        "### Q 3.8. Create a new column `surname` containing the passenger‚Äôs surname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7eef7d7",
      "metadata": {
        "id": "a7eef7d7"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b7ef837",
      "metadata": {
        "id": "2b7ef837"
      },
      "source": [
        "### **Q 3.9.** Using the engineered features, compute a summary showing:\n",
        "- average `fare` per `age_group`\n",
        "- average `family_size` per `class`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c674b42f",
      "metadata": {
        "id": "c674b42f"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0089f98e",
      "metadata": {
        "id": "0089f98e"
      },
      "source": [
        "## 4. Export Dataset\n",
        "\n",
        "Now that our dataset is clean, we might want to save time by not needing to preprocess it again.\n",
        "\n",
        "Exporting it is a good way to avoid running all cleaning steps every time you start your notebook.\n",
        "\n",
        "There are many formats you can choose, and the most common are:\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è Export to CSV\n",
        "```python\n",
        "df_clean.to_csv(\"titanic_clean.csv\", index=False)\n",
        "```\n",
        "\n",
        "- `index=False` avoids saving the DataFrame index as an extra column.\n",
        "- CSV files are human-readable and compatible with most tools.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è Export to Excel\n",
        "```python\n",
        "df_clean.to_excel(\"titanic_clean.xlsx\", index=False)\n",
        "```\n",
        "\n",
        "- Requires `openpyxl` or `xlsxwriter` installed.\n",
        "- Useful when sharing data with non-programmers.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è Export to JSON\n",
        "```python\n",
        "df_clean.to_json(\"titanic_clean.json\", orient=\"records\")\n",
        "```\n",
        "\n",
        "Common orientations:\n",
        "\n",
        "- `\"records\"` ‚Üí list of dictionaries (most common)\n",
        "- `\"split\"` ‚Üí dictionary with `index`, `columns`, `data`\n",
        "- `\"table\"` ‚Üí includes metadata, useful for interoperability\n",
        "\n",
        "---\n",
        "### ‚úîÔ∏è Loading Back the Dataset Later\n",
        "```python\n",
        "df_loaded = pd.read_csv(\"titanic_clean.csv\")\n",
        "```\n",
        "\n",
        "or:\n",
        "\n",
        "```python\n",
        "df_loaded = pd.read_json(\"titanic_clean.json\")\n",
        "```\n",
        "---\n",
        "\n",
        "**if you are curious, search for `pickle` and `parquet`.**\n",
        "\n",
        "**Now you can skip all preprocessing and jump directly into analysis.**\n",
        "\n",
        "### Q 4.1. Export the dataset to `csv`. Set `index=True` as an additional param."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c404c261",
      "metadata": {
        "id": "c404c261"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8ba341",
      "metadata": {
        "id": "bb8ba341"
      },
      "source": [
        "### Q 4.2 Load into a variable named `df_loaded`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bccdb52b",
      "metadata": {
        "id": "bccdb52b"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04417830",
      "metadata": {
        "id": "04417830"
      },
      "source": [
        "**You also could just drop the artificial index column...** `df.drop(columns=['col'], inplace=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb53c33",
      "metadata": {
        "id": "2cb53c33"
      },
      "source": [
        "### Q 4.3 Export the dataset to `csv`. Set `index=False` as an additional param."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b18fc2",
      "metadata": {
        "id": "35b18fc2"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b4ebe9",
      "metadata": {
        "id": "09b4ebe9"
      },
      "source": [
        "## 5. Final Clean Dataset\n",
        "\n",
        "### Load the Clean Dataset\n",
        "\n",
        "- **Test first with a different variable name to avoid overwriting by accident.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3a7818",
      "metadata": {
        "id": "2d3a7818"
      },
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
