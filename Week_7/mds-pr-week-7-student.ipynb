{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1343d1",
   "metadata": {},
   "source": [
    "# Week 7 â€“ Feature Engineering with Pipelines\n",
    "\n",
    ">## Learning goals\n",
    ">\n",
    ">By the end of this notebook, you should be able to:\n",
    ">\n",
    "> - Review how **preprocessing pipelines** work in scikit-learn.  \n",
    "> - Load and inspect a **real-world movies dataset** with mixed data types.  \n",
    "> - Handle **time-based features**.\n",
    "> - Implement custom cleaning and feature engineering using **`FunctionTransformer`**.  \n",
    "> - Combine **numeric** and **categorical** preprocessing with `ColumnTransformer`.  \n",
    "> - Build a **full preprocessing pipeline** using `make_pipeline`.\n",
    "> - Export a fully cleaned and transformed dataset for future use.\n",
    "___\n",
    "**Install the required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to install the required package\n",
    "#!pip install IPython\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c7e0a",
   "metadata": {},
   "source": [
    "**Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e13397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc553d1c",
   "metadata": {},
   "source": [
    "**Import datetime to handle time data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbf43d",
   "metadata": {},
   "source": [
    "**Import scikit-learn preprocessing pipelines functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import estimator_html_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a56740",
   "metadata": {},
   "source": [
    "## 1. Review of Last Class â€” Preprocessing Pipelines\n",
    "\n",
    "In the previous class, you:\n",
    "\n",
    "> - Cleaned the **Adult Income** dataset manually.  \n",
    "> - Recreated the same logic with **scikit-learn pipelines**.  \n",
    "> - Built separate pipelines for **numeric** and **categorical** features.  \n",
    "> - Combined them with `ColumnTransformer`.  \n",
    "> - Used `set_output(transform=\"pandas\")` to get back a DataFrame.  \n",
    "> - Exported the cleaned dataset to `.csv`.\n",
    ">\n",
    ">**Why was that important?\n",
    ">\n",
    "> - The preprocessing steps became **reproducible and consistent**.  \n",
    "> - You could apply exactly the same transformations to **new data**.  \n",
    "> - All cleaning logic was concentrated in a **single object** (the pipeline), instead of scattered across many cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf11389",
   "metadata": {},
   "source": [
    "## 2. The Movies Dataset\n",
    ">\n",
    ">In this class, we will work with a subset of **The Movies Dataset** (Kaggle).  \n",
    ">We will use the file **`movies_dataset.csv`**, which contains thousands of movies with:\n",
    ">\n",
    "> - Titles, languages, and textual descriptions  \n",
    "> - Budget, revenue, popularity, runtime  \n",
    "> - `release_date` (temporal information!)  \n",
    "> - Categorical attributes like `status`, `original_language`, `adult`  \n",
    "> - Some JSON-like fields such as `genres`\n",
    ">\n",
    ">**For now, we will focus on:**\n",
    ">\n",
    "> - Cleaning a subset of relevant columns  \n",
    "> - Converting `release_date` into useful features  \n",
    "> - Building a preprocessing pipeline around this.\n",
    "___\n",
    "### Q2.1. Load the dataset and show the first rows\n",
    "> - use `pd.read_csv(\"movies_metadata.csv\")`.  \n",
    "> - store the result in a DataFrame named `df`.  \n",
    "> - display the **first 5 rows** with `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9152f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046f304",
   "metadata": {},
   "source": [
    "### Q2.2. Inspect the basic structure of the dataset\n",
    ">\n",
    "> - Check the **shape** â†’ number of rows and columns.  \n",
    "> - Use `df.info()` to inspect data types and non-null counts.  \n",
    "> - Use `df.describe()` to inspect basic statistics.\n",
    ">\n",
    ">**This helps to identify:**\n",
    ">\n",
    "> - which columns are numeric  \n",
    "> - which columns are objects / strings  \n",
    "> - where there are missing values or strange types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39e51a",
   "metadata": {},
   "source": [
    "### Q2.3. Create a list of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf53603",
   "metadata": {},
   "source": [
    "### Q2.4. Create a list of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f725f8f",
   "metadata": {},
   "source": [
    "### Q2.5. Inspect the different values of categorical features\n",
    ">- use the list of categoricals that you have created earlier\n",
    ">- use `value_count()` or `.unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242d3a3",
   "metadata": {},
   "source": [
    "### Focus for this class\n",
    ">\n",
    ">**We will focus on the following columns:**\n",
    ">\n",
    "> - **`title`** â€“ movie title (string)  \n",
    "> - **`original_language`** â€“ language code (categorical)  \n",
    "> - **`adult`** â€“ whether the movie is for adults (`'True'` / `'False'`)  \n",
    "> - **`status`** â€“ release status (`Released`, `Rumored`, etc.)  \n",
    "> - **`release_date`** â€“ when the movie was released  \n",
    "> - **`budget`** â€“ production budget (numeric, but sometimes `0` or invalid)  \n",
    "> - **`revenue`** â€“ total revenue (same issues as budget)  \n",
    "> - **`runtime`** â€“ duration in minutes  \n",
    "> - **`vote_average`**, **`vote_count`**, **`popularity`** â€“ numeric indicators  \n",
    ">\n",
    ">**We will build a pipeline that:**\n",
    ">\n",
    "> - Cleans and converts these columns.  \n",
    "> - Derives time-based features.  \n",
    "> - Prepares everything for downstream ML tasks.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a6a5a",
   "metadata": {},
   "source": [
    "### Q2.6. Explore missing values and strange entries\n",
    "\n",
    "> - Compute the **percentage of missing values** per column\n",
    "> - Inspect some rows where `release_date` is missing or invalid.  \n",
    "\n",
    "This will help you understand **why** we need custom cleaning logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a11302",
   "metadata": {},
   "source": [
    "## 3. Custom Cleaning Function for Movies\n",
    "\n",
    "We will now write a **custom cleaning function** that:\n",
    "\n",
    "> - Converts `release_date` to a proper `datetime` (`errors=\"coerce\"`).  \n",
    "> - Converts `budget` and `revenue` to numeric using `pd.to_numeric(..., errors=\"coerce\")`.  \n",
    "> - Replaces **0 values** in `budget` and `revenue` with `NaN` (they usually mean \"unknown\").  \n",
    "> - Ensures `adult` is standardized as a simple `'True'` / `'False'` string or boolean.  \n",
    "\n",
    "This function will **not** be called directly on `df`.  \n",
    "Instead, we will later wrap it in a **`FunctionTransformer`** to plug it into a pipeline.\n",
    "\n",
    "### Q3.1. Implement the `basic_movies_cleaning()` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def basic_movies_cleaning(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a cleaned copy of the movies metadata DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Convert 'release_date' to datetime (errors='coerce').\n",
    "    - Convert 'budget' and 'revenue' to numeric (errors='coerce').\n",
    "    - Replace 0 values in 'budget' and 'revenue' with NaN.\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "\n",
    "    # Convert release_date to datetime\n",
    "    \n",
    "\n",
    "    # Convert budget and revenue to numeric\n",
    "    \n",
    "\n",
    "    # Replace 0 with NaN for budget and revenue\n",
    "    \n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee065e",
   "metadata": {},
   "source": [
    "### Q3.2. Test `basic_movies_cleaning` on a small sample\n",
    "> - Apply the function to a sample using `.sample()` and set `random_state=42`\n",
    "> - Call `basic_movies_cleaning(df_sample)` and inspect the result.  \n",
    "> - Check that:\n",
    ">   - `release_date` is now `datetime64[...]`  \n",
    ">   - `budget` and `revenue` are numeric  \n",
    ">   - 0 values in `budget` / `revenue` were replaced by NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925be66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07652750",
   "metadata": {},
   "source": [
    "## 4. Time-based Feature Engineering\n",
    ">We are going to work now on time features.\n",
    ">\n",
    ">The `release_date` is a good feature that can provide us a lot of information\n",
    ">\n",
    "> Example of **time-based features**, that can be extracted:\n",
    ">\n",
    "> - `release_year`  \n",
    "> - `release_month`  \n",
    "> - `release_day`  \n",
    "> - `release_weekday` (0 = Monday, 6 = Sunday)  \n",
    "> - `movie_age` (e.g. difference between current year and release year)  \n",
    ">\n",
    ">We will implement this in a separate function.  \n",
    ">Later, both functions will be combined inside a **pipeline**.\n",
    "___\n",
    "### Q4.2. First convert `release_date` column to datetime\n",
    "- use `pd.to_datetime(df['release_date'], errors='coerce')`, you can specify the `format='%Y-%m-%d'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e114605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3164d7f",
   "metadata": {},
   "source": [
    "### Q4.3. Explore some datetime attributes\n",
    "- use `dt.year`, `dt.month`, `dt.day` and `dt.weekday`\n",
    "- inspect weekday closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08209bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c45e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392e4d6",
   "metadata": {},
   "source": [
    "**Noticed that weekday starts on 0 (Monday) and ends on 6 (Sunday)?**\n",
    "___\n",
    "### Q4.4. Let's do some datetime comparinsons\n",
    ">- a) Verify for the movies within the minimum, mean, median and maximum date\n",
    ">- b) Verify for the oldest and most recent movies in the dataset\n",
    ">- c) Verify what `dt.datetime.now()` will print as output, then check it out with `Q4.3 attributes`\n",
    ">    - **Note:** use `.weekday()` instead of `.weekday`\n",
    ">- d) Verify for the difference of the current year and the `release_date` year\n",
    ">    - **Note:** what would that difference correspond to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de41b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10410270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc41c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d48a7d",
   "metadata": {},
   "source": [
    "### Q4.5. Implement `add_time_features()` function\n",
    ">```python\n",
    ">   def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    ">        \"\"\"\n",
    ">        Receives a DataFrame with a 'release_date' column (datetime)\n",
    ">        and returns a copy with new time-based features:\n",
    ">        \n",
    ">        - release_year\n",
    ">        - release_month\n",
    ">        - release_day\n",
    ">        - release_weekday\n",
    ">        - movie_age (assuming reference year = current year)\n",
    ">        \"\"\"\n",
    ">        df_new = df.copy()\n",
    ">        df_new.rename(columns={'cat__release_date': 'release_date'}, inplace=True)\n",
    ">\n",
    ">        # your code here\n",
    ">\n",
    ">        return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Receives a DataFrame with a 'release_date' column (datetime)\n",
    "    and returns a copy with new time-based features:\n",
    "    \n",
    "    - release_year\n",
    "    - release_month\n",
    "    - release_day\n",
    "    - release_weekday\n",
    "    - movie_age (assuming reference year = current year)\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    df_new.rename(columns={'cat__release_date': 'release_date'}, inplace=True)\n",
    "\n",
    "\n",
    "    # your code here\n",
    "\n",
    "\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee8d65",
   "metadata": {},
   "source": [
    "### Q4.6. Test `add_time_features` after cleaning\n",
    "\n",
    "> - Take a small sample using `.sample()`\n",
    "> - First apply `basic_movies_cleaning`  \n",
    "> - Then apply `add_time_features`  \n",
    "> - Inspect the new columns using this subset `[\"title\", \"release_date\", \"release_year\", \"release_month\", \"release_weekday\", \"movie_age\"]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc428a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print subset [\"title\", \"release_date\", \"release_year\", \"release_month\", \"release_weekday\", \"movie_age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498d6f0",
   "metadata": {},
   "source": [
    "**We are still on the surface of what we can do with `datetime` columns**\n",
    "- We are going to change the column back to object just to make it as it was before we started playing a bit with some functions\n",
    "- Remember that we are going to handle the conversion of this column in our pipeline\n",
    "___\n",
    "### Q4.6. Cast the `release_date` column back to object\n",
    ">- use `.astype(str)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5db590",
   "metadata": {},
   "source": [
    "### 5. Recap\n",
    ">\n",
    ">Up until now, what have we done?\n",
    ">\n",
    ">It seems huge because we gradually built our workflow...\n",
    "___\n",
    "### Q5.1. Take this moment to look back and summarize in steps what we have accomplished so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cd2c8",
   "metadata": {},
   "source": [
    "your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb2c2e",
   "metadata": {},
   "source": [
    "## 6. Choosing Numeric and Categorical Features\n",
    "\n",
    "We now decide which columns will be treated as **numeric** and which as **categorical** for preprocessing.\n",
    "\n",
    "For this class, we will:\n",
    "\n",
    "> - Select the following column from **categorical** list for preprocessing:\n",
    ">   - `status`  \n",
    "> - Consider all remaining **non-datetime** numeric columns as **numeric features**.  \n",
    "> - Ignore long text fields like `overview`, `tagline` for now.\n",
    "\n",
    "### Q6.1.Select the features for preprocessing\n",
    "> - create the `encode_features` list\n",
    "> - remove `release_date` if present (datetime) in numeric or categorical list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac265c8",
   "metadata": {},
   "source": [
    "## 7. Numeric and Categorical Preprocessing Pipelines\n",
    "\n",
    "We now define:\n",
    "\n",
    "> - `numeric_pipeline`\n",
    ">   - Imputes missing values with the **median**.  \n",
    ">   - Scales features using `StandardScaler`.  \n",
    ">\n",
    "> - `categorical_pipeline`\n",
    ">   - Imputes missing values with the most frequent category.\n",
    ">\n",
    "> - `encode_pipeline`\n",
    ">   - Imputes missing values with the most frequent category.\n",
    ">   - Encodes categories using `OneHotEncoder` with `handle_unknown=\"ignore\"`.\n",
    "___\n",
    "### Q7.1. Implement `numeric_pipeline`, `categorical_pipeline` and `encode_pipeline`\n",
    "- use the following:\n",
    ">```python\n",
    ">numeric_pipeline = Pipeline([\n",
    ">    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    ">    (\"scaler\", StandardScaler()),\n",
    ">])\n",
    ">\n",
    ">categorical_pipeline = Pipeline([\n",
    ">    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    ">])\n",
    ">\n",
    ">encode_pipeline = Pipeline([\n",
    ">    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    ">    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    ">])\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e021f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643058e5",
   "metadata": {},
   "source": [
    "> **Note on One-Hot Encoding Output**\n",
    ">\n",
    "> By default, `OneHotEncoder` can return a **sparse matrix**.\n",
    "> In this notebook, we set `sparse_output=False` so that the output is a **dense array**.\n",
    ">\n",
    ">   **Example of Dense Output:**\n",
    ">```console\n",
    ">                language_en  language_fr  language_pt\n",
    ">           0    1            0            0\n",
    ">           1    0            1            0\n",
    ">           2    0            0            1\n",
    ">```\n",
    ">   - Dense arrays are easier to convert into pandas DataFrames.\n",
    ">\n",
    ">   **Example of Sparse Output:**\n",
    ">```console\n",
    ">           (0, 0)\t1\n",
    ">           (1, 1)\t1\n",
    ">           (2, 2)\t1\n",
    ">```\n",
    ">   - Each row shows:\n",
    ">       - the **position** `(row_index, column_index)`  \n",
    ">       - the **value** at that position  \n",
    ">       - all other positions are implicitly **zero**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a8f79",
   "metadata": {},
   "source": [
    "## 8. Combine Everything with `ColumnTransformer`\n",
    "\n",
    "We now combine the two preprocessing pipelines into a single `ColumnTransformer` that:\n",
    "\n",
    "> - Applies `numeric_pipeline` to `numeric_features`  \n",
    "> - Applies `categorical_pipeline` to `categorical_features`  \n",
    "> - Drops remaining columns (the default behavior)\n",
    ">\n",
    ">**Example:**\n",
    ">```python\n",
    ">   full_preprocessor = ColumnTransformer(\n",
    ">        transformers=[\n",
    ">            (\"num\", numeric_pipeline, numeric_features),\n",
    ">            (\"cat\", categorical_pipeline, categorical_features),\n",
    ">            (\"enc\", encode_pipeline, encode_features),\n",
    ">        ],\n",
    ">        remainder=\"passthrough\",\n",
    ">        verbose_feature_names_out=False\n",
    ">    )\n",
    ">```\n",
    ">\n",
    ">**Note 1: The parameter `remainder=\"passthrough\"` will keep the new columns generated and make them passthrough the rest of the pipeline** \n",
    ">**Note 2: The parameter `verbose_feature_names_out=False` will mantain the original name of the columns** \n",
    "___\n",
    "### Q8.1. Create `full_preprocessor`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4cb30a",
   "metadata": {},
   "source": [
    "## 9. Full Movies Preprocessing Pipeline\n",
    "\n",
    "We can now create a **single pipeline** that:\n",
    "\n",
    "> 1. Applies `basic_movies_cleaning`  \n",
    "> 2. Applies `add_time_features`  \n",
    "> 3. Applies `full_preprocessor` (numeric + categorical + encode)\n",
    "\n",
    "We will use `make_pipeline` again and finally call `set_output(transform=\"pandas\")` so that the final result is a **DataFrame**, not a NumPy array.\n",
    "\n",
    "**Example:**\n",
    ">```python\n",
    ">    full_pipeline = make_pipeline(\n",
    ">        FunctionTransformer(basic_movies_cleaning, validate=False),\n",
    ">        FunctionTransformer(add_time_features, validate=False),\n",
    ">        full_preprocessor,\n",
    ">    )\n",
    ">\n",
    ">    full_pipeline.set_output(transform=\"pandas\")\n",
    ">```\n",
    "___\n",
    "### Q9.1. Create `full_pipeline`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a3b0c",
   "metadata": {},
   "source": [
    "## 10. Visualizing the Preprocessing Pipeline (Diagram)\n",
    "\n",
    "Scikit-learn can generate an **HTML diagram** of the entire pipeline using:\n",
    "\n",
    "> - `sklearn.utils.estimator_html_repr`  \n",
    "> - `IPython.display.HTML`\n",
    "\n",
    "This is extremely useful to **inspect the structure** of your preprocessing workflow.\n",
    "\n",
    "### Q10.1. Generate the HTML representation of `full_pipeline`\n",
    ">\n",
    "> âš ï¸ The diagram may not render outside Jupyter, but should work in a classic notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(estimator_html_repr(full_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab329a10",
   "metadata": {},
   "source": [
    "## 11. Apply the Full Pipeline to the Movies Dataset\n",
    "\n",
    "We now apply all steps in a **single call**:\n",
    "\n",
    "> - custom cleaning  \n",
    "> - time-based feature engineering  \n",
    "> - numeric, categorical and encoding preprocessing\n",
    "___\n",
    "### Q11.1. Apply `full_pipeline` to `df` and inspect the result\n",
    "> - use `fullpipeline.fit_transform(df)`\n",
    "> - Store the result in `df_clean`.  \n",
    "> - Show the first 5 rows.  \n",
    "> - Print the final shape (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5682f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b934d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8439a",
   "metadata": {},
   "source": [
    "## 12. Export the Cleaned Movies Dataset\n",
    "\n",
    "Finally, we export the processed dataset to a `.csv` file so that it can be reused.\n",
    "\n",
    "### Q12.1. Save `df_clean` as `clean_movies_preprocessed.csv` (no index).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1850b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeee866",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Extra Exercises\n",
    "\n",
    "> These are optional but recommended exercises if you want to deepen your understanding.\n",
    "\n",
    "### Q13.1. Create a `profit` and `roi` feature\n",
    "\n",
    "> - `profit = revenue - budget`  \n",
    ">\n",
    "> - **roi == Return of Investment**\n",
    ">   - `roi = revenue / budget` (be careful with division by zero / NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed2756",
   "metadata": {},
   "source": [
    "### Q13.2. Verify the number of movies released per year and plot\n",
    "- use `.groupby('release_year').size()`\n",
    "- use `.plot(kind='line')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219092c",
   "metadata": {},
   "source": [
    "### Q13.3. Verify the average budget per year and plot\n",
    "- use `.groupby(\"release_year\")[\"budget\"].mean()`\n",
    "- use `.plot(kind='line')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f89663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f08625",
   "metadata": {},
   "source": [
    "### Q13.4. Verify Monthly distribution of releases and plot\n",
    "- use `df_clean.groupby(\"release_month\").size()`\n",
    "- use `.plot(kind='line')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89279a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca23588d",
   "metadata": {},
   "source": [
    "### Q13.5. Verify movies released by weekday and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f651165c",
   "metadata": {},
   "source": [
    "### Q13.6. Verify the average popularity by movie age and plot\n",
    "- use `.groupby(\"movie_age\")[\"popularity\"].mean()`\n",
    "- use `.plot(kind='line')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86133a78",
   "metadata": {},
   "source": [
    "### ğŸ¬ğŸ¿ After those exercises you have earned the right to watch some movies!\n",
    ">\n",
    ">**Whether you prefer:**\n",
    ">ğŸ­ drama\n",
    ">ğŸš€ sci-fi\n",
    ">ğŸ˜‚ comedy\n",
    ">ğŸ¦¸ action\n",
    ">ğŸ§™â€â™‚ï¸âœ¨ fantasy\n",
    ">ğŸ’˜ romance\n",
    ">\n",
    ">â€¦go treat yourself to a well-earned film session! ğŸï¸ğŸ«"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
